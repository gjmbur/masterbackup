{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49fdc448",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Math, Latex\n",
    "from enum import Enum\n",
    "# useful: https://archive.ph/eqE2W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08bc50e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Math, Latex\n",
    "from enum import Enum\n",
    "# useful: https://archive.ph/eqE2W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c870631d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "\\ &1. \\hspace{1cm} 6 \\times \\ (5 + 3) \\newline\n",
       "\\ &2. \\hspace{1cm} 5 \\times (2^2) \\newline\n",
       "\\ &3. \\hspace{1cm} 25 \\times (5^{-1}) \\newline\n",
       "\\ &4. \\hspace{1cm} \\sqrt{\\frac{x}{49}} = 8 \\newline\n",
       "\\ &5. \\hspace{1cm} \\textit{z} = \\frac{\\textit{x}-\\mu}{\\sigma},\\hspace{0.25cm} \\text{solve for} \\hspace{.1cm}\\textit{x} \\newline\n",
       "\\ &6. \\hspace{1cm} \\textit{m} = \\textit{z} \\times \\frac{\\sigma}{\\sqrt{n}},\\hspace{0.25cm} \\text{solve for} \\hspace{.1cm}\\textit{n}\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "\\ &1. \\hspace{1cm} 6 \\times \\ (5 + 3) \\newline\n",
    "\\ &2. \\hspace{1cm} 5 \\times (2^2) \\newline\n",
    "\\ &3. \\hspace{1cm} 25 \\times (5^{-1}) \\newline\n",
    "\\ &4. \\hspace{1cm} \\sqrt{\\frac{x}{49}} = 8 \\newline\n",
    "\\ &5. \\hspace{1cm} \\textit{z} = \\frac{\\textit{x}-\\mu}{\\sigma},\\hspace{0.25cm} \\text{solve for} \\hspace{.1cm}\\textit{x} \\newline\n",
    "\\ &6. \\hspace{1cm} \\textit{m} = \\textit{z} \\times \\frac{\\sigma}{\\sqrt{n}},\\hspace{0.25cm} \\text{solve for} \\hspace{.1cm}\\textit{n}\n",
    "\\end{aligned}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c8e2d73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "\\ & \\sum_{i=1}^5 X_i \\hspace{.25cm}\\text{means}\\hspace{.25cm} X_1 + X_2 + X_3 + X_4 + X_5 \\newline\n",
       "\\ &\\text{i.e., sum all the numbers from individual one to individual five} \\newline\n",
       "\\ & \\text{Also, summation over a constant yields} \\hspace{.1cm} \\textit{n} \\times \\text{that constant,} \n",
       "\\ \\hspace{.1cm} i.e., \\newline\n",
       "\\ &\\sum_{i=1}^n k = nk\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "\\ & \\sum_{i=1}^5 X_i \\hspace{.25cm}\\text{means}\\hspace{.25cm} X_1 + X_2 + X_3 + X_4 + X_5 \\newline\n",
    "\\ &\\text{i.e., sum all the numbers from individual one to individual five} \\newline\n",
    "\\ & \\text{Also, summation over a constant yields} \\hspace{.1cm} \\textit{n} \\times \\text{that constant,} \n",
    "\\ \\hspace{.1cm} i.e., \\newline\n",
    "\\ &\\sum_{i=1}^n k = nk\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16d846e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "\\ \\textit{Y} = \\beta_{0} + \\beta_{1} \\textit{X}\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "\\ \\textit{Y} = \\beta_{0} + \\beta_{1} \\textit{X}\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f8ac529c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "\\ & \\textit{S}_{n} = \\sum_{k=0}^n ar^k \\hspace{.2cm}\\text{means}\\hspace{.25cm} a + ar + ar^1 + ... +\n",
       "\\ ar^{n-1} + ar^n \\newline\n",
       "\\ & \\text{...now multiply both sides by}\\hspace{.1cm} \\textit{r} \\hspace{.1cm} \\text{to get} ... \\newline\n",
       "\\ & \\textit{rS}_{n} = ar + ar^1 + ... + ar^{n-1} + ar^n + ar^{n+1} \\newline\n",
       "\\ & \\text{...now take the difference between the two to get...} \\newline\n",
       "\\ & \\textit{S}_{n}- \\textit{rS}_{n} = (a + ar + ar^1 + ... + ar^{n-1} + ar^n) - \n",
       "\\ (ar + ar^1 + ... + ar^{n-1} + ar^n + ar^{n+1})  \\newline\n",
       "\\ & \\text{...most terms on the RHS cancel, yielding just} \\hspace{.1cm} a- ar^{n+1}, \n",
       "\\ \\text{while the LHS factors into} \\hspace{.1cm} \\textit{S}_{n}(1-r), \\text{and thus, dividing by} (1-r), \\text{we obtain...} \\newline \n",
       "\\ & \\textit{S}_{n} = \\sum_{k=0}^n ar^k = \\frac{a(1-r^{n+1})}{1-r} \\newline\n",
       "\\ & \\text{and to get this into more familiar form, just stop the sum one item earlier:} \\newline\n",
       "\\ & \\textit{S}_{n-1} = \\sum_{k=0}^{n-1} ar^k = a + ar + ar^1 + ... + ar^{n-2} + ar^{n-1} \\newline\n",
       "\\ & \\textit{rS}_{n-1} = ar + ar^1 + ... + ar^{n-1} + ar^{n} \\newline\n",
       "\\ & \\textit{S}_{n-1}- \\textit{rS}_{n-1} = (a + ar + ar^1 + ... + ar^{n-1}) - \n",
       "\\ (ar + ar^1 + ... + ar^{n-1} + ar^n)  \\newline\n",
       "\\ & \\textit{S}_{n-1} = \\sum_{k=0}^{n-1} ar^k = \\frac{a(1-r^n)}{1-r}\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "\\ & \\textit{S}_{n} = \\sum_{k=0}^n ar^k \\hspace{.2cm}\\text{means}\\hspace{.25cm} a + ar + ar^1 + ... +\n",
    "\\ ar^{n-1} + ar^n \\newline\n",
    "\\ & \\text{...now multiply both sides by}\\hspace{.1cm} \\textit{r} \\hspace{.1cm} \\text{to get} ... \\newline\n",
    "\\ & \\textit{rS}_{n} = ar + ar^1 + ... + ar^{n-1} + ar^n + ar^{n+1} \\newline\n",
    "\\ & \\text{...now take the difference between the two to get...} \\newline\n",
    "\\ & \\textit{S}_{n}- \\textit{rS}_{n} = (a + ar + ar^1 + ... + ar^{n-1} + ar^n) - \n",
    "\\ (ar + ar^1 + ... + ar^{n-1} + ar^n + ar^{n+1})  \\newline\n",
    "\\ & \\text{...most terms on the RHS cancel, yielding just} \\hspace{.1cm} a- ar^{n+1}, \n",
    "\\ \\text{while the LHS factors into} \\hspace{.1cm} \\textit{S}_{n}(1-r), \\text{and thus, dividing by} (1-r), \\text{we obtain...} \\newline \n",
    "\\ & \\textit{S}_{n} = \\sum_{k=0}^n ar^k = \\frac{a(1-r^{n+1})}{1-r} \\newline\n",
    "\\ & \\text{and to get this into more familiar form, just stop the sum one item earlier:} \\newline\n",
    "\\ & \\textit{S}_{n-1} = \\sum_{k=0}^{n-1} ar^k = a + ar + ar^1 + ... + ar^{n-2} + ar^{n-1} \\newline\n",
    "\\ & \\textit{rS}_{n-1} = ar + ar^1 + ... + ar^{n-1} + ar^{n} \\newline\n",
    "\\ & \\textit{S}_{n-1}- \\textit{rS}_{n-1} = (a + ar + ar^1 + ... + ar^{n-1}) - \n",
    "\\ (ar + ar^1 + ... + ar^{n-1} + ar^n)  \\newline\n",
    "\\ & \\textit{S}_{n-1} = \\sum_{k=0}^{n-1} ar^k = \\frac{a(1-r^n)}{1-r}\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16f6521c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "\\ log_b(A) = X \\Leftrightarrow b^X = A\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "\\ log_b(A) = X \\Leftrightarrow b^X = A\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0673387f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "\\ \\textbf{Basic sample statistics}\n",
       "\\\\ \\text{the mean} &:  \\bar{X}\n",
       "\\\\ \\text{the median} &: X_{i =\\frac{n+1}{2}}\n",
       "\\\\ \\text{various quantiles} &: q_k \\hspace{.1cm} \\text{for which} \\hspace{.1cm} P(X \\leq q_k) =\\frac{k}{n_q}\n",
       "\\\\ \\text{the standard deviation} &: s\n",
       "\\\\ \\text{(secondarily) the variance} &: s^2\n",
       "\\\\ \\text{A quantile} \\hspace{.1cm} q_k \\hspace{.1cm}  \\text{is the value for which}\\hspace{.1cm} P(X \\leq q_k) = \\frac{k}{n_q}\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "\\ \\textbf{Basic sample statistics}\n",
    "\\\\ \\text{the mean} &:  \\bar{X}\n",
    "\\\\ \\text{the median} &: X_{i =\\frac{n+1}{2}}\n",
    "\\\\ \\text{various quantiles} &: q_k \\hspace{.1cm} \\text{for which} \\hspace{.1cm} P(X \\leq q_k) =\\frac{k}{n_q}\n",
    "\\\\ \\text{the standard deviation} &: s\n",
    "\\\\ \\text{(secondarily) the variance} &: s^2\n",
    "\\\\ \\text{A quantile} \\hspace{.1cm} q_k \\hspace{.1cm}  \\text{is the value for which}\\hspace{.1cm} P(X \\leq q_k) = \\frac{k}{n_q}\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9dd30b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "\\ \\text{If} \\hspace{.1cm} &\\bar{X} \\lt median, \\text{we have a left skew}\n",
       "\\\\ \\text{If}  \\hspace{.1cm} &\\bar{X} \\gt median, \\text{we have a right skew}\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "\\ \\text{If} \\hspace{.1cm} &\\bar{X} \\lt median, \\text{we have a left skew}\n",
    "\\\\ \\text{If}  \\hspace{.1cm} &\\bar{X} \\gt median, \\text{we have a right skew}\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8675f4da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "\\\\ \\bar{X} &= n^{-1} \\cdot \\sum_{i=1}^n X_i \\hspace{.25cm} \n",
       "\\\\[10pt] \\overline{X} &= \\frac{X_1 + X_2 + ... + X_n}{n}\n",
       "\\\\[10pt] &= \\frac{\\sum_{i=1}^n X_i}{n}\n",
       "\\\\[10pt] \\mathbb{E}[X] &= \\sum_{i = 1}^{max_k} k_i \\cdot p(X = k_i)\n",
       "\\\\ \\mathbb{E}[X] &= \\int_{-\\infty}^\\infty x  f(x) \\hspace{.25cm} dx\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "\\\\ \\bar{X} &= n^{-1} \\cdot \\sum_{i=1}^n X_i \\hspace{.25cm} \n",
    "\\\\[10pt] \\overline{X} &= \\frac{X_1 + X_2 + ... + X_n}{n}\n",
    "\\\\[10pt] &= \\frac{\\sum_{i=1}^n X_i}{n}\n",
    "\\\\[10pt] \\mathbb{E}[X] &= \\sum_{i = 1}^{max_k} k_i \\cdot p(X = k_i)\n",
    "\\\\ \\mathbb{E}[X] &= \\int_{-\\infty}^\\infty x  f(x) \\hspace{.25cm} dx\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fd99810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "\\\\ s^2 &= (n-1)^{-1} \\cdot \\sum_{i=1}^n (X_i - \\bar{X})^2 \n",
       "\\\\ &= \\frac{\\sum_{i=1}^n (X_i - \\bar{X})^2}{n-1}\n",
       "\\\\[10pt] s^2 &= \\frac{(X_1-\\bar{X})^2 + (X_2-\\bar{X})^2 + ... + (X_n-\\bar{X})^2}{n-1} \n",
       "\\\\[10pt] &= \\frac{\\sum_{i=1}^n (X_i - \\bar{X})^2}{n-1}\n",
       "\\\\[10pt] s &= \\sqrt{\\frac{\\sum_{i=1}^n (X_i - \\bar{X})^2}{n-1}}\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "\\\\ s^2 &= (n-1)^{-1} \\cdot \\sum_{i=1}^n (X_i - \\bar{X})^2 \n",
    "\\\\ &= \\frac{\\sum_{i=1}^n (X_i - \\bar{X})^2}{n-1}\n",
    "\\\\[10pt] s^2 &= \\frac{(X_1-\\bar{X})^2 + (X_2-\\bar{X})^2 + ... + (X_n-\\bar{X})^2}{n-1} \n",
    "\\\\[10pt] &= \\frac{\\sum_{i=1}^n (X_i - \\bar{X})^2}{n-1}\n",
    "\\\\[10pt] s &= \\sqrt{\\frac{\\sum_{i=1}^n (X_i - \\bar{X})^2}{n-1}}\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "69948e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "\\ \\mathbb{V}[X] &= \\mathbb{E}[(X-\\mu)^2] \\newline\n",
       "\\\\ \\mathbb{V}[X] &= \\mathbb{E}[(X-\\mu)^2] \n",
       "\\\\ &= \\mathbb{E}[X^2 - 2X\\mu +\\mu^2] \n",
       "\\\\ &= \\mathbb{E}[X^2] - \\mathbb{E}[2X\\mu] +\\mathbb{E}[\\mu^2]\n",
       "\\\\ &= \\mathbb{E}[X^2] - \\mathbb{E}[2]\\mathbb{E}[X]\\mathbb{E}[\\mu] +\\mathbb{E}[\\mu^2]\n",
       "\\\\ &= \\mathbb{E}[X^2] - (2 \\cdot \\mu \\cdot \\mu) + \\mu^2\n",
       "\\\\ &= \\mathbb{E}[X^2] - 2(\\mu^2) + \\mu^2\n",
       "\\\\ &= \\mathbb{E}[X^2] - \\mu^2\n",
       "\\\\ &= \\mathbb{E}[X^2] - \\mathbb{E}[X]^2\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "\\ \\mathbb{V}[X] &= \\mathbb{E}[(X-\\mu)^2] \\newline\n",
    "\\\\ \\mathbb{V}[X] &= \\mathbb{E}[(X-\\mu)^2] \n",
    "\\\\ &= \\mathbb{E}[X^2 - 2X\\mu +\\mu^2] \n",
    "\\\\ &= \\mathbb{E}[X^2] - \\mathbb{E}[2X\\mu] +\\mathbb{E}[\\mu^2]\n",
    "\\\\ &= \\mathbb{E}[X^2] - \\mathbb{E}[2]\\mathbb{E}[X]\\mathbb{E}[\\mu] +\\mathbb{E}[\\mu^2]\n",
    "\\\\ &= \\mathbb{E}[X^2] - (2 \\cdot \\mu \\cdot \\mu) + \\mu^2\n",
    "\\\\ &= \\mathbb{E}[X^2] - 2(\\mu^2) + \\mu^2\n",
    "\\\\ &= \\mathbb{E}[X^2] - \\mu^2\n",
    "\\\\ &= \\mathbb{E}[X^2] - \\mathbb{E}[X]^2\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a3e2335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "\\\\ \\overline{aX+b} &= a\\bar{X} + b \n",
       "\\\\ \\text{proof:}\n",
       "\\\\ \\overline{aX+b} &= \\frac{\\sum_{i=1}^n (aX+b)_i}{n}\n",
       "\\\\ &= \\frac{\\sum_{i=1}^n (aX)_i +\\sum_{i=1}^n (b)_i }{n}\n",
       "\\\\ &= \\frac{a\\sum_{i=1}^n (X)_i + nb}{n}\n",
       "\\\\ &= a \\cdot \\frac{\\sum_{i=1}^n (X)_i}{n} + \\frac{nb}{n}\n",
       "\\\\ &= a\\bar{X} + b\n",
       "\\\\[20pt]\n",
       "\\\\ \\overline{X} + \\overline{Y} &= \\overline{X+Y}\n",
       "\\\\ \\text{proof:}\n",
       "\\\\ \\overline{X} + \\overline{Y} &= \\frac{\\sum_{i=1}^n X_i}{n} + \\frac{\\sum_{i=1}^n Y_i}{n}\n",
       "\\\\ &= \\frac{\\sum_{i=1}^n X_i + \\sum_{i=1}^n Y_i}{n}\n",
       "\\\\ &= \\frac{n(\\bar{X}) + n(\\bar{Y})}{n}\n",
       "\\\\ \\overline{X} + \\overline{Y} &= {\\bar{X} + \\bar{Y}}\n",
       "\\\\ & \\text{An important caveat here is that this is only true if} \n",
       "\\\\ & n_X = n_Y \\text{which we do generally assume in this context;}\n",
       "\\\\ & \\text{otherwise, vector addition is undefined. But, sometimes in}\n",
       "\\\\ & \\text{statistics, we add unequal sample sizes anyways, in which case}\n",
       "\\\\ & \\text{this property notoriously does not hold, as in Simpson's paradox}\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "\\\\ \\overline{aX+b} &= a\\bar{X} + b \n",
    "\\\\ \\text{proof:}\n",
    "\\\\ \\overline{aX+b} &= \\frac{\\sum_{i=1}^n (aX+b)_i}{n}\n",
    "\\\\ &= \\frac{\\sum_{i=1}^n (aX)_i +\\sum_{i=1}^n (b)_i }{n}\n",
    "\\\\ &= \\frac{a\\sum_{i=1}^n (X)_i + nb}{n}\n",
    "\\\\ &= a \\cdot \\frac{\\sum_{i=1}^n (X)_i}{n} + \\frac{nb}{n}\n",
    "\\\\ &= a\\bar{X} + b\n",
    "\\\\[20pt]\n",
    "\\\\ \\overline{X} + \\overline{Y} &= \\overline{X+Y}\n",
    "\\\\ \\text{proof:}\n",
    "\\\\ \\overline{X} + \\overline{Y} &= \\frac{\\sum_{i=1}^n X_i}{n} + \\frac{\\sum_{i=1}^n Y_i}{n}\n",
    "\\\\ &= \\frac{\\sum_{i=1}^n X_i + \\sum_{i=1}^n Y_i}{n}\n",
    "\\\\ &= \\frac{n(\\bar{X}) + n(\\bar{Y})}{n}\n",
    "\\\\ \\overline{X} + \\overline{Y} &= {\\bar{X} + \\bar{Y}}\n",
    "\\\\ & \\text{An important caveat here is that this is only true if} \n",
    "\\\\ & n_X = n_Y \\text{which we do generally assume in this context;}\n",
    "\\\\ & \\text{otherwise, vector addition is undefined. But, sometimes in}\n",
    "\\\\ & \\text{statistics, we add unequal sample sizes anyways, in which case}\n",
    "\\\\ & \\text{this property notoriously does not hold, as in Simpson's paradox}\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47ab6da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "\\\\ & \\sum_{i=1}^n (X_i - \\bar{X})  \n",
       "\\\\ &= \\sum_{i=1}^n (X_i) - \\sum_{i=1}^n (\\bar{X})\n",
       "\\\\ &= \\text{all Xs summed} - \\text{the sum over the constant} \\hspace{.1cm} \\bar{X}\n",
       "\\\\ &= (n \\cdot \\bar{X}) - (n \\cdot \\bar{X})\n",
       "\\\\ &= 0\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "\\\\ & \\sum_{i=1}^n (X_i - \\bar{X})  \n",
    "\\\\ &= \\sum_{i=1}^n (X_i) - \\sum_{i=1}^n (\\bar{X})\n",
    "\\\\ &= \\text{all Xs summed} - \\text{the sum over the constant} \\hspace{.1cm} \\bar{X}\n",
    "\\\\ &= (n \\cdot \\bar{X}) - (n \\cdot \\bar{X})\n",
    "\\\\ &= 0\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e27e485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "\\\\ s^2 &= \\frac{\\sum_{i=1}^n (X_i - \\bar{X})^2}{n-1}\n",
       "\\\\[10pt] &= \\frac{(6-10)^2 + (8-10)^2 + (10-10)^2 + (12-10)^2 + (14-10)^2}{5-1}\n",
       "\\\\[10pt] &= \\frac{(-4)^2 + (-2)^2 + (0)^2 + (2)^2 + (4)^2}{5-1}\n",
       "\\\\[10pt] &= \\frac{(16 + 4 + 0 + 4 + 16)}{5-1}\n",
       "\\\\[10pt] &= \\frac{(40)}{5-1}\n",
       "\\\\[10pt] s^2 &= 10\n",
       "\\\\[10pt] s &= \\sqrt{\\frac{\\sum_{i=1}^n (X_i - \\bar{X})^2}{n-1}}\n",
       "\\\\[10pt]  &= \\sqrt{10}\n",
       "\\\\[10pt] s &= 3.16\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "\\\\ s^2 &= \\frac{\\sum_{i=1}^n (X_i - \\bar{X})^2}{n-1}\n",
    "\\\\[10pt] &= \\frac{(6-10)^2 + (8-10)^2 + (10-10)^2 + (12-10)^2 + (14-10)^2}{5-1}\n",
    "\\\\[10pt] &= \\frac{(-4)^2 + (-2)^2 + (0)^2 + (2)^2 + (4)^2}{5-1}\n",
    "\\\\[10pt] &= \\frac{(16 + 4 + 0 + 4 + 16)}{5-1}\n",
    "\\\\[10pt] &= \\frac{(40)}{5-1}\n",
    "\\\\[10pt] s^2 &= 10\n",
    "\\\\[10pt] s &= \\sqrt{\\frac{\\sum_{i=1}^n (X_i - \\bar{X})^2}{n-1}}\n",
    "\\\\[10pt]  &= \\sqrt{10}\n",
    "\\\\[10pt] s &= 3.16\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "12de6d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "\\ & \\text{Goal: minimize sum of squares of} \\hspace{.1cm}(X_i-k)\n",
       "\\\\ SS(k) &= \\sum_{i=1}^n (X_i - k)^2\n",
       "\\\\ &= \\sum_{i=1}^n (X_i^2 - 2kX_i + k^2)\n",
       "\\\\ &= \\sum_{i=1}^n (X_i^2) - \\sum_{i=1}^n 2kX_i + \\sum_{i=1}^n (k^2)\n",
       "\\\\ &= n \\bar{X} - 2k\\bar{X} + n(k^2)\n",
       "\\\\ \\frac{dSS(k)}{dk} &= \\bar{X} - 2\\bar{X} + 2n(k)\n",
       "\\\\ & \\text{Setting the derivative equal to zero, we have...}\n",
       "\\\\ 0 &= \\bar{X} - 2\\bar{X} + 2n(k)\n",
       "\\\\ \\bar{X} &= 2n(k)\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "\\ & \\text{Goal: minimize sum of squares of} \\hspace{.1cm}(X_i-k)\n",
    "\\\\ SS(k) &= \\sum_{i=1}^n (X_i - k)^2\n",
    "\\\\ &= \\sum_{i=1}^n (X_i^2 - 2kX_i + k^2)\n",
    "\\\\ &= \\sum_{i=1}^n (X_i^2) - \\sum_{i=1}^n 2kX_i + \\sum_{i=1}^n (k^2)\n",
    "\\\\ &= n \\bar{X} - 2k\\bar{X} + n(k^2)\n",
    "\\\\ \\frac{dSS(k)}{dk} &= \\bar{X} - 2\\bar{X} + 2n(k)\n",
    "\\\\ & \\text{Setting the derivative equal to zero, we have...}\n",
    "\\\\ 0 &= \\bar{X} - 2\\bar{X} + 2n(k)\n",
    "\\\\ \\bar{X} &= 2n(k)\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "74c1b92e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "\\ & \\text{Goal: minimize sum of squares of} \\hspace{.1cm}(X_i-k)\n",
       "\\\\ SS(k) &= \\sum_{i=1}^n (X_i - k)^2\n",
       "\\\\ &= \\sum_{i=1}^n (X_i^2 - 2kX_i + k^2)\n",
       "\\\\ &= \\sum_{i=1}^n (X_i^2) - \\sum_{i=1}^n 2kX_i + \\sum_{i=1}^n (k^2)\n",
       "\\\\ & \\text{Now, we use a quick trick and give variable labels to stuff we don't care about}\n",
       "\\\\ & \\text{Here, the actual sum of Xs is not relevant to what relative value minimizes them}\n",
       "\\\\ &= A - 2k\\bar{X} + n(k^2)\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "\\ & \\text{Goal: minimize sum of squares of} \\hspace{.1cm}(X_i-k)\n",
    "\\\\ SS(k) &= \\sum_{i=1}^n (X_i - k)^2\n",
    "\\\\ &= \\sum_{i=1}^n (X_i^2 - 2kX_i + k^2)\n",
    "\\\\ &= \\sum_{i=1}^n (X_i^2) - \\sum_{i=1}^n 2kX_i + \\sum_{i=1}^n (k^2)\n",
    "\\\\ & \\text{Now, we use a quick trick and give variable labels to stuff we don't care about}\n",
    "\\\\ & \\text{Here, the actual sum of Xs is not relevant to what relative value minimizes them}\n",
    "\\\\ &= A - 2k\\bar{X} + n(k^2)\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "47c855fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "\\ & \\text{Goal: minimize sum of squares of} \\hspace{.1cm}(X_i-k)\n",
       "\\\\ & SS(k) = \\sum_{i=1}^n (X_i - k)^2\n",
       "\\\\ & \\text{So, we want to find where} \\frac{dSS(k)}{dk} = 0\n",
       "\\\\ & \\text{Now find} \\frac{d}{dk} \\sum_{i=1}^n (X_i - k)^2 \\hspace{.1cm} \\text{noting that the derivative can be moved inside}\n",
       "\\\\ & \\sum_{i=1}^n \\frac{d}{dk} (X_i - k)^2\n",
       "\\\\ & \\text{using the chain rule—i.e.,} \\hspace{.1cm} y = f(x), x = g(z), \\frac{dy}{dz} = \\frac{dy}{dx} \\frac{dx}{dz}\\hspace{.1cm}\\text{—we have...}\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "\\ & \\text{Goal: minimize sum of squares of} \\hspace{.1cm}(X_i-k)\n",
    "\\\\ & SS(k) = \\sum_{i=1}^n (X_i - k)^2\n",
    "\\\\ & \\text{So, we want to find where} \\frac{dSS(k)}{dk} = 0\n",
    "\\\\ & \\text{Now find} \\frac{d}{dk} \\sum_{i=1}^n (X_i - k)^2 \\hspace{.1cm} \\text{noting that the derivative can be moved inside}\n",
    "\\\\ & \\sum_{i=1}^n \\frac{d}{dk} (X_i - k)^2\n",
    "\\\\ & \\text{using the chain rule—i.e.,} \\hspace{.1cm} y = f(x), x = g(z), \\frac{dy}{dz} = \\frac{dy}{dx} \\frac{dx}{dz}\\hspace{.1cm}\\text{—we have...}\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ffd93c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "\\ & \\text{CDF of X:} \\hspace{.1cm} F(x) = \\mathbb{P}(X ≤ x) \\newline\n",
       "\\ &\\text{the height of the function is the} \\newline\n",
       "\\ &\\text{probability of observing a realization} \\newline\n",
       "\\ &\\text{(little) x of the random variable X} \\newline\n",
       "\\ &\\text{that has this value or one smaller.} \\newline\n",
       "\\\\[10pt] & \\text{PMF of X:} \\hspace{.1cm} p(x) = \\mathbb{P}({X = x}) \\newline\n",
       "\\ & \\text{the height of the function is} \\newline\n",
       "\\ &\\text{the probability of observing some} \\newline\n",
       "\\ & \\text{concrete value of [big] X which} \\newline\n",
       "\\ & \\text{we denote with [little] x}\n",
       "\\\\[10pt] & \\text{PDF of X:} \\hspace{.1cm} f(x) \\hspace{.1cm} \\text{for which} \\hspace{.1cm} \\newline\n",
       "\\ & \\mathbb{P}(c \\leq X \\leq d) = \\int_c^d f(x) \\hspace{.2cm} dx \\newline\n",
       "\\ & \\text{i.e., the area under the curve} \\newline\n",
       "\\ & \\text{of f(x) between C and D is } \\newline\n",
       "\\ & \\text{the probability of X taking} \\newline\n",
       "\\ & \\text{on a value between those two.}\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "\\ & \\text{CDF of X:} \\hspace{.1cm} F(x) = \\mathbb{P}(X ≤ x) \\newline\n",
    "\\ &\\text{the height of the function is the} \\newline\n",
    "\\ &\\text{probability of observing a realization} \\newline\n",
    "\\ &\\text{(little) x of the random variable X} \\newline\n",
    "\\ &\\text{that has this value or one smaller.} \\newline\n",
    "\\\\[10pt] & \\text{PMF of X:} \\hspace{.1cm} p(x) = \\mathbb{P}({X = x}) \\newline\n",
    "\\ & \\text{the height of the function is} \\newline\n",
    "\\ &\\text{the probability of observing some} \\newline\n",
    "\\ & \\text{concrete value of [big] X which} \\newline\n",
    "\\ & \\text{we denote with [little] x}\n",
    "\\\\[10pt] & \\text{PDF of X:} \\hspace{.1cm} f(x) \\hspace{.1cm} \\text{for which} \\hspace{.1cm} \\newline\n",
    "\\ & \\mathbb{P}(c \\leq X \\leq d) = \\int_c^d f(x) \\hspace{.2cm} dx \\newline\n",
    "\\ & \\text{i.e., the area under the curve} \\newline\n",
    "\\ & \\text{of f(x) between C and D is } \\newline\n",
    "\\ & \\text{the probability of X taking} \\newline\n",
    "\\ & \\text{on a value between those two.}\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d81efcf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "\\text{mean dot product}_{X, Y} &= \\frac{\\sum_{i=1}^n {(X_i})(Y_i)}{n-1} \\newline\n",
       "cov_{X, Y} &= \\frac{\\sum_{i=1}^n {(X_i - \\bar{X})(Y_i - \\bar{Y})}}{n-1} \\newline\n",
       "\\\\[10pt]r_{X, Y} &= \\frac{\\sum_{i=1}^n \\frac{(X_i - \\bar{X})}{s_X}\\frac{(Y_i - \\bar{Y})}{s_Y}}{n-1}\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "\\text{mean dot product}_{X, Y} &= \\frac{\\sum_{i=1}^n {(X_i})(Y_i)}{n-1} \\newline\n",
    "cov_{X, Y} &= \\frac{\\sum_{i=1}^n {(X_i - \\bar{X})(Y_i - \\bar{Y})}}{n-1} \\newline\n",
    "\\\\[10pt]r_{X, Y} &= \\frac{\\sum_{i=1}^n \\frac{(X_i - \\bar{X})}{s_X}\\frac{(Y_i - \\bar{Y})}{s_Y}}{n-1}\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "8fee42a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "\\ & \\text{we've already proved that the mean is a linear operator; let's prove it roughly for s}\n",
       "\\\\[10pt] s &= \\sqrt{\\frac{\\sum_{i=1}^n (X_i - \\bar{X})^2}{n-1}} \\newline\n",
       "\\ & \\text{first we'll add a constant b}\n",
       "\\\\[10pt] s_{aX+b} &= \\sqrt{\\frac{\\sum_{i=1}^n [(X_i+b) - \\overline{X+b}]^2}{n-1}} \\newline\n",
       "\\ & \\text{let's focus on the inside first}\n",
       "\\\\[10pt] &= ... \\sum [(X_i+b) - \\overline{X+b}]^2\n",
       "\\\\[10pt] &= ... \\sum [(X_i+b) - (\\overline{X}+b)]^2 \\hspace{.1cm} \\text{by linearity of the mean}\n",
       "\\\\[10pt] &= ... \\sum (X_i - \\overline{X})^2 \\hspace{.1cm} \\text{QED} \\newline\n",
       "\\ & \\text{now we'll multiply by a constant a}\n",
       "\\\\[10pt] &= ... \\sum [(aX_i) - \\overline{aX}]^2\n",
       "\\\\[10pt] &= ... \\sum [a^2(X_i)^2 - 2a^2X_i\\bar{X} + (\\overline{a}^2 \\overline{X}^2)]\n",
       "\\\\[10pt] &= ... a^2 \\cdot \\sum (X_i^2 - 2X_i\\bar{X} + \\overline{X}^2) \\newline\n",
       "\\ & \\text{bring back in the whole formula}\n",
       "\\\\[10pt] s_{aX+b} &= a \\cdot \\sqrt{\\frac{\\sum_{i=1}^n [(X_i) - \\overline{X}]^2}{n-1}} \\newline\n",
       "\\ & \\text{N.b. that a would never be negative in context}\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "\\ & \\text{we've already proved that the mean is a linear operator; let's prove it roughly for s}\n",
    "\\\\[10pt] s &= \\sqrt{\\frac{\\sum_{i=1}^n (X_i - \\bar{X})^2}{n-1}} \\newline\n",
    "\\ & \\text{first we'll add a constant b}\n",
    "\\\\[10pt] s_{aX+b} &= \\sqrt{\\frac{\\sum_{i=1}^n [(X_i+b) - \\overline{X+b}]^2}{n-1}} \\newline\n",
    "\\ & \\text{let's focus on the inside first}\n",
    "\\\\[10pt] &= ... \\sum [(X_i+b) - \\overline{X+b}]^2\n",
    "\\\\[10pt] &= ... \\sum [(X_i+b) - (\\overline{X}+b)]^2 \\hspace{.1cm} \\text{by linearity of the mean}\n",
    "\\\\[10pt] &= ... \\sum (X_i - \\overline{X})^2 \\hspace{.1cm} \\text{QED} \\newline\n",
    "\\ & \\text{now we'll multiply by a constant a}\n",
    "\\\\[10pt] &= ... \\sum [(aX_i) - \\overline{aX}]^2\n",
    "\\\\[10pt] &= ... \\sum [a^2(X_i)^2 - 2a^2X_i\\bar{X} + (\\overline{a}^2 \\overline{X}^2)]\n",
    "\\\\[10pt] &= ... a^2 \\cdot \\sum (X_i^2 - 2X_i\\bar{X} + \\overline{X}^2) \\newline\n",
    "\\ & \\text{bring back in the whole formula}\n",
    "\\\\[10pt] s_{aX+b} &= a \\cdot \\sqrt{\\frac{\\sum_{i=1}^n [(X_i) - \\overline{X}]^2}{n-1}} \\newline\n",
    "\\ & \\text{N.b. that a would never be negative in context}\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "2018aa51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "\\text{mean dot product}_{X, Y} &= \\frac{\\sum_{i=1}^n {(X_i})(Y_i)}{n-1} \\newline\n",
       "\\text{mean dot product}_{X+a, Y+b} &= \\frac{\\sum_{i=1}^n {(X+a_i})(Y+b_i)}{n-1} \\newline\n",
       "\\text{mean dot product}_{X+a, Y+b} &= \\frac{(\\sum{X_i}+\\sum{a})(\\sum{Y_i}+\\sum{b})}{n-1} \\newline                  \n",
       "\\text{mean dot product}_{X+a, Y+b} &= \\frac{(na\\cdot\\sum{X_i})(nb \\cdot \\sum{Y_i})}{n-1} \\newline                        \n",
       "\\text{mean dot product}_{X+a, Y+b} &= na \\cdot nb \\cdot \\text{mean dot product}\n",
       "\\\\[10pt]cov_{X, Y} &= \\frac{\\sum_{i=1}^n {(X_i - \\bar{X})(Y_i - \\bar{Y})}}{n-1}\n",
       "\\\\[5pt]cov_{X+a, Y+b} &= \\frac{\\sum_{i=1}^n {((X_i+a)) - \\overline{X+a})((Y_i+b) - \\overline{Y+b})}}{n-1}\n",
       "\\\\[5pt] &= \\frac{\\sum_{i=1}^n {((X_i+a)) - \\overline{X+a})((Y_i+b) - \\overline{Y+b})}}{n-1} \\newline\n",
       "\\\\[5pt] &\\text{focus here on just the X term for simplicity}\n",
       "\\\\[10pt] &= \\frac{(\\sum{X_i}+\\sum{a})-\\sum{\\overline{X+a}}...}{n-1} \\newline \n",
       "\\\\[5pt] &= \\frac{\\sum{X_i}+na-\\sum{\\overline{X}}-\\sum{a}...}{n-1} \\newline \n",
       "\\\\[5pt] &= \\frac{\\sum{X_i}+na-\\sum{\\overline{X}}-na...}{n-1} \\newline \n",
       "\\\\[5pt] &= \\frac{\\sum{X_i}-\\overline{X}...}{n-1} \\hspace{.1cm} \\text{QED} \\newline \n",
       "\\\\[10pt]r_{X, Y} &= \\frac{\\sum_{i=1}^n \\frac{(X_i - \\bar{X})}{s_X}\\frac{(Y_i - \\bar{Y})}{s_Y}}{n-1}\n",
       "\\\\[5pt] &\\text{again, focus here on just the X term for simplicity (Y follows by extension; the n-1 is a constant)}\n",
       "\\\\[10pt]r_{X, Y} &= {\\sum_{i=1}^n \\frac{(X_i - \\bar{X})}{s_X}}...\n",
       "\\\\[10pt]r_{aX, Y} &= {\\sum_{i=1}^n \\frac{aX_i - \\overline{aX}}{s_{aX}}}...\n",
       "\\\\[10pt]r_{aX, Y} &= {\\sum_{i=1}^n \\frac{a \\cdot (X_i - \\overline{X}}{a \\cdot s_{X}}}...\n",
       "\\\\[10pt]r_{aX, Y} &= {\\sum_{i=1}^n \\frac{(X_i - \\overline{X})}{s_{X}}}...\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "\\text{mean dot product}_{X, Y} &= \\frac{\\sum_{i=1}^n {(X_i})(Y_i)}{n-1} \\newline\n",
    "\\text{mean dot product}_{X+a, Y+b} &= \\frac{\\sum_{i=1}^n {(X+a_i})(Y+b_i)}{n-1} \\newline\n",
    "\\text{mean dot product}_{X+a, Y+b} &= \\frac{(\\sum{X_i}+\\sum{a})(\\sum{Y_i}+\\sum{b})}{n-1} \\newline                  \n",
    "\\text{mean dot product}_{X+a, Y+b} &= \\frac{(na\\cdot\\sum{X_i})(nb \\cdot \\sum{Y_i})}{n-1} \\newline                        \n",
    "\\text{mean dot product}_{X+a, Y+b} &= na \\cdot nb \\cdot \\text{mean dot product}\n",
    "\\\\[10pt]cov_{X, Y} &= \\frac{\\sum_{i=1}^n {(X_i - \\bar{X})(Y_i - \\bar{Y})}}{n-1}\n",
    "\\\\[5pt]cov_{X+a, Y+b} &= \\frac{\\sum_{i=1}^n {((X_i+a)) - \\overline{X+a})((Y_i+b) - \\overline{Y+b})}}{n-1}\n",
    "\\\\[5pt] &= \\frac{\\sum_{i=1}^n {((X_i+a)) - \\overline{X+a})((Y_i+b) - \\overline{Y+b})}}{n-1} \\newline\n",
    "\\\\[5pt] &\\text{focus here on just the X term for simplicity}\n",
    "\\\\[10pt] &= \\frac{(\\sum{X_i}+\\sum{a})-\\sum{\\overline{X+a}}...}{n-1} \\newline \n",
    "\\\\[5pt] &= \\frac{\\sum{X_i}+na-\\sum{\\overline{X}}-\\sum{a}...}{n-1} \\newline \n",
    "\\\\[5pt] &= \\frac{\\sum{X_i}+na-\\sum{\\overline{X}}-na...}{n-1} \\newline \n",
    "\\\\[5pt] &= \\frac{\\sum{X_i}-\\overline{X}...}{n-1} \\hspace{.1cm} \\text{QED} \\newline \n",
    "\\\\[10pt]r_{X, Y} &= \\frac{\\sum_{i=1}^n \\frac{(X_i - \\bar{X})}{s_X}\\frac{(Y_i - \\bar{Y})}{s_Y}}{n-1}\n",
    "\\\\[5pt] &\\text{again, focus here on just the X term for simplicity (Y follows by extension; the n-1 is a constant)}\n",
    "\\\\[10pt]r_{X, Y} &= {\\sum_{i=1}^n \\frac{(X_i - \\bar{X})}{s_X}}...\n",
    "\\\\[10pt]r_{aX, Y} &= {\\sum_{i=1}^n \\frac{aX_i - \\overline{aX}}{s_{aX}}}...\n",
    "\\\\[10pt]r_{aX, Y} &= {\\sum_{i=1}^n \\frac{a \\cdot (X_i - \\overline{X}}{a \\cdot s_{X}}}...\n",
    "\\\\[10pt]r_{aX, Y} &= {\\sum_{i=1}^n \\frac{(X_i - \\overline{X})}{s_{X}}}...\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "67ec8b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "\\\\[10pt]cov_{X, Y} &= \\frac{\\sum_{i=1}^n {(X_i - \\bar{X})(Y_i - \\bar{Y})}}{n-1}\n",
       "\\\\[10pt]cov_{aX, bY} &= \\frac{\\sum_{i=1}^n {(aX_i - \\overline{aX})(bY_i - \\overline{bY})}}{n-1}\n",
       "\\\\[10pt] &\\text{for simplicity, ignore the denominator and Y-terms for now}\n",
       "\\\\[10pt] &= \\sum{(aX_i - \\overline{aX})}\n",
       "\\\\[10pt] &= \\sum{aX_i} - \\sum{\\overline{aX}}\n",
       "\\\\[10pt] &= a\\sum{X_i} - (a)\\cdot \\sum{\\overline{X}})\n",
       "\\\\[10pt] &= a(\\sum{X_i} - \\sum{\\overline{X}})\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "\\\\[10pt]cov_{X, Y} &= \\frac{\\sum_{i=1}^n {(X_i - \\bar{X})(Y_i - \\bar{Y})}}{n-1}\n",
    "\\\\[10pt]cov_{aX, bY} &= \\frac{\\sum_{i=1}^n {(aX_i - \\overline{aX})(bY_i - \\overline{bY})}}{n-1}\n",
    "\\\\[10pt] &\\text{for simplicity, ignore the denominator and Y-terms for now}\n",
    "\\\\[10pt] &= \\sum{(aX_i - \\overline{aX})}\n",
    "\\\\[10pt] &= \\sum{aX_i} - \\sum{\\overline{aX}}\n",
    "\\\\[10pt] &= a\\sum{X_i} - (a)\\cdot \\sum{\\overline{X}})\n",
    "\\\\[10pt] &= a(\\sum{X_i} - \\sum{\\overline{X}})\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "40d961e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "\\\\[10pt]cov_{X, Y} &= \\frac{\\sum_{i=1}^n {(X_i - \\bar{X})(Y_i - \\bar{Y})}}{n-1}\n",
       "\\\\[10pt] &\\text{Alternative expression no. 1 starts by factoring out the standard deviations}\n",
       "\\\\[10pt]r_{X, Y} &= \\frac{\\sum_{i=1}^n \\frac{(X_i - \\bar{X})}{s_X}\\frac{(Y_i - \\bar{Y})}{s_Y}}{n-1}\n",
       "\\\\[10pt] &= \\frac{1}{{s_X}{s_Y}} \\cdot \\frac{\\sum_{i=1}^n (X_i - \\bar{X})(Y_i - \\bar{Y})}{n-1}\n",
       "\\\\[10pt] &= \\frac{ cov_{X, Y}}{{s_X}{s_Y}}\n",
       "\\\\[10pt] &\\text{Alternative expression no. 2 starts from there and writes out the standard deviations}\n",
       "\\\\[10pt] &= \\frac{{\\frac{\\sum(X_i - \\bar{X})(Y_i - \\bar{Y})}{n-1}}}{\\sqrt{\\frac{{\\sum(X_i - \\bar{X})^2}}{n-1}}\n",
       "                                                        \\cdot \\sqrt{\\frac{\\sum{(Y_i - \\bar{Y})^2}}{n-1}}}\n",
       "\\\\[10pt] &= \\frac{{\\frac{\\sum(X_i - \\bar{X})(Y_i - \\bar{Y})}{n-1}}}{\\frac{\\sqrt{\\sum(X_i - \\bar{X})^2}\n",
       "                                                        \\cdot \\sqrt{\\sum{(Y_i - \\bar{Y})^2}}}{n-1}}\n",
       "\\\\[10pt] &= \\frac{\\sum(X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sqrt{\\sum(X_i - \\bar{X})^2}\n",
       "                                                        \\cdot \\sqrt{\\sum{(Y_i - \\bar{Y})^2}}}\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "\\\\[10pt]cov_{X, Y} &= \\frac{\\sum_{i=1}^n {(X_i - \\bar{X})(Y_i - \\bar{Y})}}{n-1}\n",
    "\\\\[10pt] &\\text{Alternative expression no. 1 starts by factoring out the standard deviations}\n",
    "\\\\[10pt]r_{X, Y} &= \\frac{\\sum_{i=1}^n \\frac{(X_i - \\bar{X})}{s_X}\\frac{(Y_i - \\bar{Y})}{s_Y}}{n-1}\n",
    "\\\\[10pt] &= \\frac{1}{{s_X}{s_Y}} \\cdot \\frac{\\sum_{i=1}^n (X_i - \\bar{X})(Y_i - \\bar{Y})}{n-1}\n",
    "\\\\[10pt] &= \\frac{ cov_{X, Y}}{{s_X}{s_Y}}\n",
    "\\\\[10pt] &\\text{Alternative expression no. 2 starts from there and writes out the standard deviations}\n",
    "\\\\[10pt] &= \\frac{{\\frac{\\sum(X_i - \\bar{X})(Y_i - \\bar{Y})}{n-1}}}{\\sqrt{\\frac{{\\sum(X_i - \\bar{X})^2}}{n-1}}\n",
    "                                                        \\cdot \\sqrt{\\frac{\\sum{(Y_i - \\bar{Y})^2}}{n-1}}}\n",
    "\\\\[10pt] &= \\frac{{\\frac{\\sum(X_i - \\bar{X})(Y_i - \\bar{Y})}{n-1}}}{\\frac{\\sqrt{\\sum(X_i - \\bar{X})^2}\n",
    "                                                        \\cdot \\sqrt{\\sum{(Y_i - \\bar{Y})^2}}}{n-1}}\n",
    "\\\\[10pt] &= \\frac{\\sum(X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sqrt{\\sum(X_i - \\bar{X})^2}\n",
    "                                                        \\cdot \\sqrt{\\sum{(Y_i - \\bar{Y})^2}}}\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6656093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "\\\\[10pt]cov_{X, Y} &= \\frac{\\sum_{i=1}^n {(X_i - \\bar{X})(Y_i - \\bar{Y})}}{n-1}\n",
       "\\\\[10pt]r_{X, Y} &= \\frac{ cov_{X, Y}}{{s_X}{s_Y}}\n",
       "\\\\[10pt] &= \\frac{\\sum_{i=1}^n \\frac{(X_i - \\bar{X})}{s_X}\\frac{(Y_i - \\bar{Y})}{s_Y}}{n-1}\n",
       "\\\\[10pt] &= \\frac{\\sum(X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sqrt{\\sum(X_i - \\bar{X})^2}\n",
       "                                                        \\cdot \\sqrt{\\sum{(Y_i - \\bar{Y})^2}}}\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "\\\\[10pt]cov_{X, Y} &= \\frac{\\sum_{i=1}^n {(X_i - \\bar{X})(Y_i - \\bar{Y})}}{n-1}\n",
    "\\\\[10pt]r_{X, Y} &= \\frac{ cov_{X, Y}}{{s_X}{s_Y}}\n",
    "\\\\[10pt] &= \\frac{\\sum_{i=1}^n \\frac{(X_i - \\bar{X})}{s_X}\\frac{(Y_i - \\bar{Y})}{s_Y}}{n-1}\n",
    "\\\\[10pt] &= \\frac{\\sum(X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sqrt{\\sum(X_i - \\bar{X})^2}\n",
    "                                                        \\cdot \\sqrt{\\sum{(Y_i - \\bar{Y})^2}}}\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "0a3748e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "\\\\[10pt]r_{X, Y} &= \\frac{\\sum_{i=1}^n \\frac{(X_i - \\bar{X})}{s_X}\\frac{(Y_i - \\bar{Y})}{s_Y}}{n-1}\n",
       "\\\\[10pt]r_{X, Y} &= \\frac{\\sum_{i=1}^n \\frac{(X_i - 20)}{s_X}\\frac{(Y_i - 42)}{s_Y}}{5-1}\n",
       "\\\\[10pt]r_{X, Y} &= \\frac{\\sum_{i=1}^n \\frac{(X_i - 20)}{13.69}\\frac{(Y_i - 42)}{s_Y}}{5-1}\n",
       "\\\\[10pt]r_{X, Y} &= \\frac{\\sum_{i=1}^n \\frac{(X_i - 20)}{13.69}\\frac{(Y_i - 42)}{21.68}}{4}\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "\\\\[10pt]r_{X, Y} &= \\frac{\\sum_{i=1}^n \\frac{(X_i - \\bar{X})}{s_X}\\frac{(Y_i - \\bar{Y})}{s_Y}}{n-1}\n",
    "\\\\[10pt]r_{X, Y} &= \\frac{\\sum_{i=1}^n \\frac{(X_i - 20)}{s_X}\\frac{(Y_i - 42)}{s_Y}}{5-1}\n",
    "\\\\[10pt]r_{X, Y} &= \\frac{\\sum_{i=1}^n \\frac{(X_i - 20)}{13.69}\\frac{(Y_i - 42)}{s_Y}}{5-1}\n",
    "\\\\[10pt]r_{X, Y} &= \\frac{\\sum_{i=1}^n \\frac{(X_i - 20)}{13.69}\\frac{(Y_i - 42)}{21.68}}{4}\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b1d8486f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "\\begin{split}\n",
       "    &\\textbf{Measures of central tendency} \\\\\n",
       "    \\\\[10pt] &\\overline{X} = \\frac{X_1 + X_2 + ... + X_n}{n}\n",
       "    \\\\[10pt] &\\text{the median}: X_{i =\\frac{n+1}{2}} \\hspace{.1cm} \\text{(interpolate if not present in data)}\n",
       "    \\\\ &\\textbf{Measures of dispersion}\n",
       "    \\\\ &\\text{five-number summary}: X_{min}, Q_1, Q_2, Q_3, X_{max}\n",
       "    \\\\[10pt] s &= \\sqrt{\\frac{\\sum_{i=1}^n (X_i - \\bar{X})^2}{n-1}}\n",
       "\\end{split}\n",
       "\\qquad\\hspace{.1cm}\\qquad\n",
       "\\begin{split}\n",
       "    &\\text{text} \\\\\n",
       "    dx+ey+f-xvg-yvh-vi &= 0\n",
       "\\end{split}\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "\\begin{split}\n",
    "    &\\textbf{Measures of central tendency} \\\\\n",
    "    \\\\[10pt] &\\overline{X} = \\frac{X_1 + X_2 + ... + X_n}{n}\n",
    "    \\\\[10pt] &\\text{the median}: X_{i =\\frac{n+1}{2}} \\hspace{.1cm} \\text{(interpolate if not present in data)}\n",
    "    \\\\ &\\textbf{Measures of dispersion}\n",
    "    \\\\ &\\text{five-number summary}: X_{min}, Q_1, Q_2, Q_3, X_{max}\n",
    "    \\\\[10pt] s &= \\sqrt{\\frac{\\sum_{i=1}^n (X_i - \\bar{X})^2}{n-1}}\n",
    "\\end{split}\n",
    "\\qquad\\hspace{.1cm}\\qquad\n",
    "\\begin{split}\n",
    "    &\\text{text} \\\\\n",
    "    dx+ey+f-xvg-yvh-vi &= 0\n",
    "\\end{split}\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d14c4e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{array}{ll}\n",
       "\\textbf{Measures of central tendency} & \\textbf{Measures of association}\\cr\n",
       "\\overline{X} = \\frac{\\sum_{i=1}^n X_i}{n} & \\cr\n",
       "\\text{the median}: X_{i =\\frac{n+1}{2}} \\hspace{.1cm} \\text{(interpolate if not present in data)}  & cov_{X, Y} = \\frac{\\sum_{i=1}^n {(X_i - \\bar{X})(Y_i - \\bar{Y})}}{n-1} \\cr\n",
       "\\text{five-number summary}: X_{min}, Q_1, Q_2, Q_3, X_{max} & r_{X, Y} = \\frac{\\sum_{i=1}^n \\frac{(X_i - \\overline{X})}{s_X}\\frac{(Y_i - \\overline{Y})}{s_Y}}{n-1} = \\frac{COV_{X, Y}}{s_X \\cdot s_Y} \\cr\n",
       "\\textit{s} = \\sqrt{\\frac{\\sum_{i=1}^n (X_i - \\overline{X})^2}{n-1}} \n",
       "\\textit{z} \\text{-scores are quantiles for some theoretical distributions, e.g. Normal} \\cr\n",
       "\\textit{z} = \\frac{X - \\mu}{\\sigma} \\cr\n",
       "\\textit{z}\\text{-tables give cumulative probabilities for different} \\hspace{.1cm} z_i\n",
       "\\end{array}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{array}{ll}\n",
    "\\textbf{Measures of central tendency} & \\textbf{Measures of association}\\cr\n",
    "\\overline{X} = \\frac{\\sum_{i=1}^n X_i}{n} & \\cr\n",
    "\\text{the median}: X_{i =\\frac{n+1}{2}} \\hspace{.1cm} \\text{(interpolate if not present in data)}  & cov_{X, Y} = \\frac{\\sum_{i=1}^n {(X_i - \\bar{X})(Y_i - \\bar{Y})}}{n-1} \\cr\n",
    "\\text{five-number summary}: X_{min}, Q_1, Q_2, Q_3, X_{max} & r_{X, Y} = \\frac{\\sum_{i=1}^n \\frac{(X_i - \\overline{X})}{s_X}\\frac{(Y_i - \\overline{Y})}{s_Y}}{n-1} = \\frac{COV_{X, Y}}{s_X \\cdot s_Y} \\cr\n",
    "\\textit{s} = \\sqrt{\\frac{\\sum_{i=1}^n (X_i - \\overline{X})^2}{n-1}} \n",
    "\\textit{z} \\text{-scores are quantiles for some theoretical distributions, e.g. Normal} \\cr\n",
    "\\textit{z} = \\frac{X - \\mu}{\\sigma} \\cr\n",
    "\\textit{z}\\text{-tables give cumulative probabilities for different} \\hspace{.1cm} z_i\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d62882cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{array}{ll}\n",
       "\\textbf{Measures of central tendency} & \\textbf{Measures of association}\\cr\n",
       "\\overline{X} = \\frac{\\sum_{i=1}^n X_i}{n} & r_{X, Y} = \\frac{\\sum_{i=1}^n \\frac{(X_i - \\overline{X})}{s_X}\\frac{(Y_i - \\overline{Y})}{s_Y}}{n-1}\\cr\n",
       "\\text{the median}: X_{i =\\frac{n+1}{2}} \\hspace{.1cm} \\text{(interpolate if not present in data)}  & \\cr\n",
       "\\text{five-number summary}: X_{min}, Q_1, Q_2, Q_3, X_{max} & \\widehat{\\beta}_1 = r \\cdot \\frac{s_Y}{s_X} \\cr\n",
       "\\textit{s} = \\sqrt{\\frac{\\sum_{i=1}^n (X_i - \\overline{X})^2}{n-1}} & \\widehat{\\beta}_0 = \\overline{Y} - (\\widehat{\\beta}_1 \\cdot \\overline{X}) \\cr\n",
       "\\textit{z} \\text{-scores are quantiles for some theoretical distributions, e.g. Normal} \\cr\n",
       "\\textit{z} = \\frac{X - \\mu}{\\sigma} \\cr\n",
       "\\textit{z}\\text{-tables give cumulative probabilities for different} \\hspace{.1cm} z_i\n",
       "\\end{array}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{array}{ll}\n",
    "\\textbf{Measures of central tendency} & \\textbf{Measures of association}\\cr\n",
    "\\overline{X} = \\frac{\\sum_{i=1}^n X_i}{n} & r_{X, Y} = \\frac{\\sum_{i=1}^n \\frac{(X_i - \\overline{X})}{s_X}\\frac{(Y_i - \\overline{Y})}{s_Y}}{n-1}\\cr\n",
    "\\text{the median}: X_{i =\\frac{n+1}{2}} \\hspace{.1cm} \\text{(interpolate if not present in data)}  & \\cr\n",
    "\\text{five-number summary}: X_{min}, Q_1, Q_2, Q_3, X_{max} & \\widehat{\\beta}_1 = r \\cdot \\frac{s_Y}{s_X} \\cr\n",
    "\\textit{s} = \\sqrt{\\frac{\\sum_{i=1}^n (X_i - \\overline{X})^2}{n-1}} & \\widehat{\\beta}_0 = \\overline{Y} - (\\widehat{\\beta}_1 \\cdot \\overline{X}) \\cr\n",
    "\\textit{z} \\text{-scores are quantiles for some theoretical distributions, e.g. Normal} \\cr\n",
    "\\textit{z} = \\frac{X - \\mu}{\\sigma} \\cr\n",
    "\\textit{z}\\text{-tables give cumulative probabilities for different} \\hspace{.1cm} z_i\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1bd4bbab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "\\widehat{\\beta}_1 = r \\cdot \\frac{s_Y}{s_X} \\cr\n",
       "\\widehat{\\beta}_0 = \\overline{Y} - (\\widehat{\\beta}_1 \\cdot \\overline{X})\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "\\widehat{\\beta}_1 = r \\cdot \\frac{s_Y}{s_X} \\cr\n",
    "\\widehat{\\beta}_0 = \\overline{Y} - (\\widehat{\\beta}_1 \\cdot \\overline{X})\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "579247f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "& \\text{So, we assert that the error term and predictor are unrelated. This implies the following relationship...} \\newline\n",
       "& r_{X, U} = 0 \\newline\n",
       "& \\text{...which in turn implies...} \\newline\n",
       "& COV(X, U) = 0\n",
       "\\\\[10pt] &= \\frac{\\sum_{i=1}^n {(X_i - \\bar{X})(U_i - \\bar{U})}}{n-1} \\newline\n",
       "& \\text{...and the denominator is an irrelevant scaling factor, so...} \n",
       "\\\\[5pt] & \\sum_{i=1}^n (X_i - \\bar{X})(U_i - \\bar{U}) = 0 \\hspace{.1cm} \\text{is our key condition} \n",
       "\\\\[5pt] &\\text{For notational simplicity, let's replace this with linear algebra notation.} \\newline\n",
       "\\\\[5pt] &\\text{Let's also assume centered variables, without loss of generality.} \\newline\n",
       "&\\text{In the subsequent proof, I show why this is a very minor assumption.} \\newline\n",
       "&\\text{So, if our variables are centered, we really just have the summed product of the two for all} \\hspace{.1cm} i. \\newline\n",
       "&\\text{In linear algebra, this is simply known as the \"dot product\" of two vectors. Thus,} \\newline\n",
       "& \\vec{X} \\cdot \\vec{U} = 0 \\hspace{.1cm} \\text{is the key condition. Then, replace the error with...} \\newline\n",
       "& \\vec{U} = \\vec{Y} - (\\beta_0 + \\beta_1\\vec{X}) \\newline\n",
       "& \\vec{U} = \\vec{Y} - \\beta_1\\vec{X} \\hspace{.1cm} \\text{(the intercept is zero for centered vectors)} \\newline \n",
       "& \\vec{X} \\cdot (\\vec{Y} - \\beta_1\\vec{X}) = 0  \\newline\n",
       "& (\\vec{X} \\cdot \\vec{Y}) - (\\vec{X} \\cdot \\beta_1\\vec{X}) = 0 \\newline\n",
       "&  (\\vec{X} \\cdot \\beta_1\\vec{X}) = (\\vec{X} \\cdot \\vec{Y}) \\newline\n",
       "&  (\\vec{X} \\cdot \\vec{X}\\beta_1) = (\\vec{X} \\cdot \\vec{Y}) \\newline\n",
       "& \\text{Now, rewrite these with summation notation.} \\newline\n",
       "& \\sum_{i=1}^n (X_i - \\bar{X}) \\cdot \\sum_{i=1}^n (X_i - \\bar{X}) \\cdot \\beta_1 = \\sum_{i=1}^n (X_i - \\bar{X}) \\cdot \\sum_{i=1}^n (Y_i - \\bar{Y})\n",
       "\\\\ & \\beta_1 = \\frac{\\sum_{i=1}^n (X_i - \\bar{X}) \\cdot \\sum_{i=1}^n (Y_i - \\bar{Y})} {\\sum_{i=1}^n (X_i - \\bar{X}) \\cdot \\sum_{i=1}^n (X_i - \\bar{X})}\n",
       "\\\\ & \\text{Finally, note that this looks very similar to the alternate correlation formula we learned ...}\n",
       "\\\\ & \\text{...but with twice the sum of squares of X in the denominator.} \n",
       "\\\\ & \\text{Happily, if we multiply that alternate correlation expression by the root of the sum of squares of Y over that of X...}\n",
       "\\\\ & \\text{...we just get the regression slope. That is...}\n",
       "\\\\[10pt] &\\beta_1 =  (r = \\frac{\\sum(X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sqrt{\\sum(X_i - \\bar{X})^2}\n",
       "                                                        \\cdot \\sqrt{\\sum{(Y_i - \\bar{Y})^2}}}) \n",
       "            \\cdot \\frac{\\sqrt{\\sum{(Y_i - \\bar{Y})^2}}}{\\sqrt{\\sum(X_i - \\bar{X})^2}} \\newline\n",
       "\\\\[10pt] &=  (r = \\frac{\\sum(X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sqrt{\\sum(X_i - \\bar{X})^2}\n",
       "                                                        \\cdot \\sqrt{\\sum{(Y_i - \\bar{Y})^2}}}) \n",
       "            \\cdot \\frac{s_Y}{s_X} \\newline\n",
       "\\\\[10pt] &=  r \\cdot \\frac{s_Y}{s_X} \n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "& \\text{So, we assert that the error term and predictor are unrelated. This implies the following relationship...} \\newline\n",
    "& r_{X, U} = 0 \\newline\n",
    "& \\text{...which in turn implies...} \\newline\n",
    "& COV(X, U) = 0\n",
    "\\\\[10pt] &= \\frac{\\sum_{i=1}^n {(X_i - \\bar{X})(U_i - \\bar{U})}}{n-1} \\newline\n",
    "& \\text{...and the denominator is an irrelevant scaling factor, so...} \n",
    "\\\\[5pt] & \\sum_{i=1}^n (X_i - \\bar{X})(U_i - \\bar{U}) = 0 \\hspace{.1cm} \\text{is our key condition} \n",
    "\\\\[5pt] &\\text{For notational simplicity, let's replace this with linear algebra notation.} \\newline\n",
    "\\\\[5pt] &\\text{Let's also assume centered variables, without loss of generality.} \\newline\n",
    "&\\text{In the subsequent proof, I show why this is a very minor assumption.} \\newline\n",
    "&\\text{So, if our variables are centered, we really just have the summed product of the two for all} \\hspace{.1cm} i. \\newline\n",
    "&\\text{In linear algebra, this is simply known as the \"dot product\" of two vectors. Thus,} \\newline\n",
    "& \\vec{X} \\cdot \\vec{U} = 0 \\hspace{.1cm} \\text{is the key condition. Then, replace the error with...} \\newline\n",
    "& \\vec{U} = \\vec{Y} - (\\beta_0 + \\beta_1\\vec{X}) \\newline\n",
    "& \\vec{U} = \\vec{Y} - \\beta_1\\vec{X} \\hspace{.1cm} \\text{(the intercept is zero for centered vectors)} \\newline \n",
    "& \\vec{X} \\cdot (\\vec{Y} - \\beta_1\\vec{X}) = 0  \\newline\n",
    "& (\\vec{X} \\cdot \\vec{Y}) - (\\vec{X} \\cdot \\beta_1\\vec{X}) = 0 \\newline\n",
    "&  (\\vec{X} \\cdot \\beta_1\\vec{X}) = (\\vec{X} \\cdot \\vec{Y}) \\newline\n",
    "&  (\\vec{X} \\cdot \\vec{X}\\beta_1) = (\\vec{X} \\cdot \\vec{Y}) \\newline\n",
    "& \\text{Now, rewrite these with summation notation.} \\newline\n",
    "& \\sum_{i=1}^n (X_i - \\bar{X}) \\cdot \\sum_{i=1}^n (X_i - \\bar{X}) \\cdot \\beta_1 = \\sum_{i=1}^n (X_i - \\bar{X}) \\cdot \\sum_{i=1}^n (Y_i - \\bar{Y})\n",
    "\\\\ & \\beta_1 = \\frac{\\sum_{i=1}^n (X_i - \\bar{X}) \\cdot \\sum_{i=1}^n (Y_i - \\bar{Y})} {\\sum_{i=1}^n (X_i - \\bar{X}) \\cdot \\sum_{i=1}^n (X_i - \\bar{X})}\n",
    "\\\\ & \\text{Finally, note that this looks very similar to the alternate correlation formula we learned ...}\n",
    "\\\\ & \\text{...but with twice the sum of squares of X in the denominator.} \n",
    "\\\\ & \\text{Happily, if we multiply that alternate correlation expression by the root of the sum of squares of Y over that of X...}\n",
    "\\\\ & \\text{...we just get the regression slope. That is...}\n",
    "\\\\[10pt] &\\beta_1 =  (r = \\frac{\\sum(X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sqrt{\\sum(X_i - \\bar{X})^2}\n",
    "                                                        \\cdot \\sqrt{\\sum{(Y_i - \\bar{Y})^2}}}) \n",
    "            \\cdot \\frac{\\sqrt{\\sum{(Y_i - \\bar{Y})^2}}}{\\sqrt{\\sum(X_i - \\bar{X})^2}} \\newline\n",
    "\\\\[10pt] &=  (r = \\frac{\\sum(X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sqrt{\\sum(X_i - \\bar{X})^2}\n",
    "                                                        \\cdot \\sqrt{\\sum{(Y_i - \\bar{Y})^2}}}) \n",
    "            \\cdot \\frac{s_Y}{s_X} \\newline\n",
    "\\\\[10pt] &=  r \\cdot \\frac{s_Y}{s_X} \n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ce715e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "& \\text{Let's first derive the formula for the intercept. We'll do this primarily so we can focus on the slope later.} \\newline\n",
       "& \\text{We can imagine breaking the outcome vector into two orthogonal components:} \\newline\n",
       "& \\vec{Y} = (\\overline{Y})\\vec{1} + \\vec{y}_{dev} \\hspace{.1cm} \\text{where \"dev\" indicates deviations about the mean} \\newline\n",
       "& \\text{...and we can thus treat the problem of projecting Y into two totally-different subspaces.} \\newline\n",
       "& \\text{First, let's focus on the intercept. We'll write out the whole regression equation first.} \\newline\n",
       "& \\vec{Y} = \\beta_0 + \\beta_1\\vec{X} \\newline\n",
       "& (\\overline{Y})\\vec{1} + \\vec{y}_{dev}  = \\beta_0 + \\beta_1[(\\overline{X})\\vec{1} + \\vec{x}_{dev}] \\newline\n",
       "& (\\overline{Y})\\vec{1} + \\vec{y}_{dev}  = (\\beta_0)\\vec{1} + \\beta_1[(\\overline{X})\\vec{1} + \\vec{x}_{dev}] \\newline\n",
       "& (\\overline{Y})\\vec{1} + \\vec{y}_{dev}  = (\\beta_0 + \\beta_1\\overline{X})\\vec{1} + \\beta_1\\vec{x}_{dev} \\newline\n",
       "& \\text{So, we'll just focus now on the intercept. We want the following to things to be as close as possible.} \\newline\n",
       "& (\\overline{Y})\\vec{1} = (\\beta_0 + \\beta_1\\overline{X})\\vec{1} \\newline\n",
       "& (\\overline{Y} - \\beta_1\\overline{X})\\vec{1} = (\\beta_0)\\vec{1} \\newline\n",
       "& \\text{And here the obvious solution is to just let} \\hspace{.05cm} \\beta_0 \\hspace{.05cm} \\text{equal} \\hspace{.05cm} \\overline{Y} - \\beta_1\\overline{X}\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "& \\text{Let's first derive the formula for the intercept. We'll do this primarily so we can focus on the slope later.} \\newline\n",
    "& \\text{We can imagine breaking the outcome vector into two orthogonal components:} \\newline\n",
    "& \\vec{Y} = (\\overline{Y})\\vec{1} + \\vec{y}_{dev} \\hspace{.1cm} \\text{where \"dev\" indicates deviations about the mean} \\newline\n",
    "& \\text{...and we can thus treat the problem of projecting Y into two totally-different subspaces.} \\newline\n",
    "& \\text{First, let's focus on the intercept. We'll write out the whole regression equation first.} \\newline\n",
    "& \\vec{Y} = \\beta_0 + \\beta_1\\vec{X} \\newline\n",
    "& (\\overline{Y})\\vec{1} + \\vec{y}_{dev}  = \\beta_0 + \\beta_1[(\\overline{X})\\vec{1} + \\vec{x}_{dev}] \\newline\n",
    "& (\\overline{Y})\\vec{1} + \\vec{y}_{dev}  = (\\beta_0)\\vec{1} + \\beta_1[(\\overline{X})\\vec{1} + \\vec{x}_{dev}] \\newline\n",
    "& (\\overline{Y})\\vec{1} + \\vec{y}_{dev}  = (\\beta_0 + \\beta_1\\overline{X})\\vec{1} + \\beta_1\\vec{x}_{dev} \\newline\n",
    "& \\text{So, we'll just focus now on the intercept. We want the following to things to be as close as possible.} \\newline\n",
    "& (\\overline{Y})\\vec{1} = (\\beta_0 + \\beta_1\\overline{X})\\vec{1} \\newline\n",
    "& (\\overline{Y} - \\beta_1\\overline{X})\\vec{1} = (\\beta_0)\\vec{1} \\newline\n",
    "& \\text{And here the obvious solution is to just let} \\hspace{.05cm} \\beta_0 \\hspace{.05cm} \\text{equal} \\hspace{.05cm} \\overline{Y} - \\beta_1\\overline{X}\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ef7af73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "& \\text{The purpose here is to extend the proof to the general case of multiple predictors.} \\newline\n",
       "& \\text{This is actually quite simple: we just recall that the key condition is for each predictor...} \\newline\n",
       "& \\text{to be orthogonal to the residual, and we can write the dot product between two vectors as...} \\newline\n",
       "& \\text{the matrix product of the transpose of the vector in itself. Then, just stack the vectors!} \\newline\n",
       "& \\vec{x_1}^T \\vec{r} = 0 \\newline\n",
       "& \\vec{x_2}^T \\vec{r} = 0 \\newline\n",
       "& \\text{...etc...} \\newline\n",
       "& = X^T \\vec{r} = 0 \\newline\n",
       "& = X^T (\\vec{y} - X\\vec{\\beta}) = 0 \\newline\n",
       "& = X^T\\vec{y} - X^TX\\vec{\\beta} = 0 \\newline\n",
       "& X^T\\vec{y} = X^TX\\vec{\\beta} \\newline\n",
       "& (X^TX)^{-1}X^T\\vec{y} = \\vec{\\beta}\n",
       "\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "& \\text{The purpose here is to extend the proof to the general case of multiple predictors.} \\newline\n",
    "& \\text{This is actually quite simple: we just recall that the key condition is for each predictor...} \\newline\n",
    "& \\text{to be orthogonal to the residual, and we can write the dot product between two vectors as...} \\newline\n",
    "& \\text{the matrix product of the transpose of the vector in itself. Then, just stack the vectors!} \\newline\n",
    "& \\vec{x_1}^T \\vec{r} = 0 \\newline\n",
    "& \\vec{x_2}^T \\vec{r} = 0 \\newline\n",
    "& \\text{...etc...} \\newline\n",
    "& = X^T \\vec{r} = 0 \\newline\n",
    "& = X^T (\\vec{y} - X\\vec{\\beta}) = 0 \\newline\n",
    "& = X^T\\vec{y} - X^TX\\vec{\\beta} = 0 \\newline\n",
    "& X^T\\vec{y} = X^TX\\vec{\\beta} \\newline\n",
    "& (X^TX)^{-1}X^T\\vec{y} = \\vec{\\beta}\n",
    "\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1cea0fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "& \\text{Now, we have the harder problem of figuring out how to choose} \\hspace{.05cm} \\beta_1 \\text{such that}\\newline\n",
       "& \\vec{y}_{dev}  = \\beta_1\\vec{x}_{dev} \\hspace{.05cm} \\text{...are as close as possible}. \\newline\n",
       "& \\text{One way to solve this is to start with the key assumption that the error term in the population is uncorrelated with X.} \\newline \n",
       "& r_{X, U} = 0 \\newline\n",
       "& \\text{...which in turn implies...} \\newline\n",
       "& COV(X, U) = 0\n",
       "\\\\[10pt] &= \\frac{\\sum_{i=1}^n {(X_i - \\bar{X})(U_i - \\bar{U})}}{n-1} \\newline\n",
       "& \\text{...and the denominator is an irrelevant scaling factor, so...} \n",
       "\\\\[5pt] & \\sum_{i=1}^n (X_i - \\bar{X})(U_i - \\bar{U}) = 0 \\hspace{.1cm} \\text{is our key condition} \n",
       "\\\\[5pt] &\\text{For notational simplicity, let's replace this with linear algebra notation.} \\newline\n",
       "\\\\[5pt] &\\text{Note that here was centered variables effectively since we're focusing only on deviations.} \\newline\n",
       "&\\text{So, if our variables are centered, we really just have the summed product of the two for all} \\hspace{.1cm} i. \\newline\n",
       "&\\text{In linear algebra, this is simply known as the \"dot product\" of two vectors. Thus,} \\newline\n",
       "& \\vec{X} \\cdot \\vec{U} = 0 \\hspace{.1cm} \\text{is the key condition. Then, replace the error with...} \\newline\n",
       "& \\vec{U} = \\vec{Y} - \\beta_1\\vec{X} \\hspace{.1cm} \\text{(the intercept is zero for centered vectors)} \\newline \n",
       "& \\vec{X} \\cdot (\\vec{Y} - \\beta_1\\vec{X}) = 0  \\newline\n",
       "& (\\vec{X} \\cdot \\vec{Y}) - (\\vec{X} \\cdot \\beta_1\\vec{X}) = 0 \\newline\n",
       "&  (\\vec{X} \\cdot \\beta_1\\vec{X}) = (\\vec{X} \\cdot \\vec{Y}) \\newline\n",
       "&  (\\vec{X} \\cdot \\vec{X}\\beta_1) = (\\vec{X} \\cdot \\vec{Y}) \\newline\n",
       "& \\text{Now, rewrite these with summation notation.} \\newline\n",
       "& \\sum_{i=1}^n (X_i - \\bar{X}) \\cdot \\sum_{i=1}^n (X_i - \\bar{X}) \\cdot \\beta_1 = \\sum_{i=1}^n (X_i - \\bar{X}) \\cdot \\sum_{i=1}^n (Y_i - \\bar{Y})\n",
       "\\\\ & \\beta_1 = \\frac{\\sum_{i=1}^n (X_i - \\bar{X}) \\cdot \\sum_{i=1}^n (Y_i - \\bar{Y})} {\\sum_{i=1}^n (X_i - \\bar{X}) \\cdot \\sum_{i=1}^n (X_i - \\bar{X})}\n",
       "\\\\ & \\text{Finally, note that this looks very similar to the alternate correlation formula we learned ...}\n",
       "\\\\ & \\text{...but with twice the sum of squares of X in the denominator.} \n",
       "\\\\ & \\text{Happily, if we multiply that alternate correlation expression by the root of the sum of squares of Y over that of X...}\n",
       "\\\\ & \\text{...we just get the regression slope. That is...}\n",
       "\\\\[10pt] &\\beta_1 =  (r = \\frac{\\sum(X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sqrt{\\sum(X_i - \\bar{X})^2}\n",
       "                                                        \\cdot \\sqrt{\\sum{(Y_i - \\bar{Y})^2}}}) \n",
       "            \\cdot \\frac{\\sqrt{\\sum{(Y_i - \\bar{Y})^2}}}{\\sqrt{\\sum(X_i - \\bar{X})^2}} \\newline\n",
       "\\\\[10pt] &=  (r = \\frac{\\sum(X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sqrt{\\sum(X_i - \\bar{X})^2}\n",
       "                                                        \\cdot \\sqrt{\\sum{(Y_i - \\bar{Y})^2}}}) \n",
       "            \\cdot \\frac{s_Y}{s_X} \\newline\n",
       "\\\\[10pt] &=  r \\cdot \\frac{s_Y}{s_X} \n",
       "\\end{aligned} \n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "& \\text{Now, we have the harder problem of figuring out how to choose} \\hspace{.05cm} \\beta_1 \\text{such that}\\newline\n",
    "& \\vec{y}_{dev}  = \\beta_1\\vec{x}_{dev} \\hspace{.05cm} \\text{...are as close as possible}. \\newline\n",
    "& \\text{One way to solve this is to start with the key assumption that the error term in the population is uncorrelated with X.} \\newline \n",
    "& r_{X, U} = 0 \\newline\n",
    "& \\text{...which in turn implies...} \\newline\n",
    "& COV(X, U) = 0\n",
    "\\\\[10pt] &= \\frac{\\sum_{i=1}^n {(X_i - \\bar{X})(U_i - \\bar{U})}}{n-1} \\newline\n",
    "& \\text{...and the denominator is an irrelevant scaling factor, so...} \n",
    "\\\\[5pt] & \\sum_{i=1}^n (X_i - \\bar{X})(U_i - \\bar{U}) = 0 \\hspace{.1cm} \\text{is our key condition} \n",
    "\\\\[5pt] &\\text{For notational simplicity, let's replace this with linear algebra notation.} \\newline\n",
    "\\\\[5pt] &\\text{Note that here was centered variables effectively since we're focusing only on deviations.} \\newline\n",
    "&\\text{So, if our variables are centered, we really just have the summed product of the two for all} \\hspace{.1cm} i. \\newline\n",
    "&\\text{In linear algebra, this is simply known as the \"dot product\" of two vectors. Thus,} \\newline\n",
    "& \\vec{X} \\cdot \\vec{U} = 0 \\hspace{.1cm} \\text{is the key condition. Then, replace the error with...} \\newline\n",
    "& \\vec{U} = \\vec{Y} - \\beta_1\\vec{X} \\hspace{.1cm} \\text{(the intercept is zero for centered vectors)} \\newline \n",
    "& \\vec{X} \\cdot (\\vec{Y} - \\beta_1\\vec{X}) = 0  \\newline\n",
    "& (\\vec{X} \\cdot \\vec{Y}) - (\\vec{X} \\cdot \\beta_1\\vec{X}) = 0 \\newline\n",
    "&  (\\vec{X} \\cdot \\beta_1\\vec{X}) = (\\vec{X} \\cdot \\vec{Y}) \\newline\n",
    "&  (\\vec{X} \\cdot \\vec{X}\\beta_1) = (\\vec{X} \\cdot \\vec{Y}) \\newline\n",
    "& \\text{Now, rewrite these with summation notation.} \\newline\n",
    "& \\sum_{i=1}^n (X_i - \\bar{X}) \\cdot \\sum_{i=1}^n (X_i - \\bar{X}) \\cdot \\beta_1 = \\sum_{i=1}^n (X_i - \\bar{X}) \\cdot \\sum_{i=1}^n (Y_i - \\bar{Y})\n",
    "\\\\ & \\beta_1 = \\frac{\\sum_{i=1}^n (X_i - \\bar{X}) \\cdot \\sum_{i=1}^n (Y_i - \\bar{Y})} {\\sum_{i=1}^n (X_i - \\bar{X}) \\cdot \\sum_{i=1}^n (X_i - \\bar{X})}\n",
    "\\\\ & \\text{Finally, note that this looks very similar to the alternate correlation formula we learned ...}\n",
    "\\\\ & \\text{...but with twice the sum of squares of X in the denominator.} \n",
    "\\\\ & \\text{Happily, if we multiply that alternate correlation expression by the root of the sum of squares of Y over that of X...}\n",
    "\\\\ & \\text{...we just get the regression slope. That is...}\n",
    "\\\\[10pt] &\\beta_1 =  (r = \\frac{\\sum(X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sqrt{\\sum(X_i - \\bar{X})^2}\n",
    "                                                        \\cdot \\sqrt{\\sum{(Y_i - \\bar{Y})^2}}}) \n",
    "            \\cdot \\frac{\\sqrt{\\sum{(Y_i - \\bar{Y})^2}}}{\\sqrt{\\sum(X_i - \\bar{X})^2}} \\newline\n",
    "\\\\[10pt] &=  (r = \\frac{\\sum(X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sqrt{\\sum(X_i - \\bar{X})^2}\n",
    "                                                        \\cdot \\sqrt{\\sum{(Y_i - \\bar{Y})^2}}}) \n",
    "            \\cdot \\frac{s_Y}{s_X} \\newline\n",
    "\\\\[10pt] &=  r \\cdot \\frac{s_Y}{s_X} \n",
    "\\end{aligned} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f0d67ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "&\\text{Begin by establishing some key ideas that will become useful later.} \\hspace{.1cm} \\mathbb{P} \\text{(A | B) denotes the probability of A once we know B.} \\newline\n",
       "&\\text{You might think about it pictorially (we'll see this later): if S is the overall sample space, B is a \"sub-area\" of S}. \\newline\n",
       "&\\text{If} \\hspace{.1cm} \\mathbb{P}(A) \\hspace{.1cm} \\text{is the ratio of A's area to that of S,} \\hspace{.1cm} \\mathbb{P}(A|B) \\hspace{.1cm}\n",
       "\\text{should logically be the ratio of the overlap of A} \\hspace{.1cm} \\textit{and} \\hspace{.1cm} \\text{B to B.} \\newline\n",
       "&\\text{Therefore,}  \\hspace{.1cm} \\mathbb{P}(A|B) \\hspace{.1cm} = \\frac{\\mathbb{P}(A \\cap B)}{\\mathbb{P}(B)} \\newline\n",
       "&\\text{And, logically,}  \\hspace{.1cm} \\mathbb{P}(B|A) \\hspace{.1cm} = \\frac{\\mathbb{P}(B \\cap A)}{\\mathbb{P}(A)} \\newline\n",
       "&\\text{And finally, with a bit of algebra...} {\\mathbb{P}(A \\cap B)} = \\mathbb{P}(A | B) \\cdot {\\mathbb{P}(B)} \n",
       "= {\\mathbb{P}(B | A) \\cdot \\mathbb{P}(A)} \\newline\n",
       "&\\text{...and, finally, we derive Bayes' theorem, i.e.,} \\newline\n",
       "&\\mathbb{P}(B | A) = \\frac{\\mathbb{P} (A | B) \\cdot \\mathbb{P}(B)} {\\mathbb{P}(A)}  \\newline\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "&\\text{Begin by establishing some key ideas that will become useful later.} \\hspace{.1cm} \\mathbb{P} \\text{(A | B) denotes the probability of A once we know B.} \\newline\n",
    "&\\text{You might think about it pictorially (we'll see this later): if S is the overall sample space, B is a \"sub-area\" of S}. \\newline\n",
    "&\\text{If} \\hspace{.1cm} \\mathbb{P}(A) \\hspace{.1cm} \\text{is the ratio of A's area to that of S,} \\hspace{.1cm} \\mathbb{P}(A|B) \\hspace{.1cm}\n",
    "\\text{should logically be the ratio of the overlap of A} \\hspace{.1cm} \\textit{and} \\hspace{.1cm} \\text{B to B.} \\newline\n",
    "&\\text{Therefore,}  \\hspace{.1cm} \\mathbb{P}(A|B) \\hspace{.1cm} = \\frac{\\mathbb{P}(A \\cap B)}{\\mathbb{P}(B)} \\newline\n",
    "&\\text{And, logically,}  \\hspace{.1cm} \\mathbb{P}(B|A) \\hspace{.1cm} = \\frac{\\mathbb{P}(B \\cap A)}{\\mathbb{P}(A)} \\newline\n",
    "&\\text{And finally, with a bit of algebra...} {\\mathbb{P}(A \\cap B)} = \\mathbb{P}(A | B) \\cdot {\\mathbb{P}(B)} \n",
    "= {\\mathbb{P}(B | A) \\cdot \\mathbb{P}(A)} \\newline\n",
    "&\\text{...and, finally, we derive Bayes' theorem, i.e.,} \\newline\n",
    "&\\mathbb{P}(B | A) = \\frac{\\mathbb{P} (A | B) \\cdot \\mathbb{P}(B)} {\\mathbb{P}(A)}  \\newline\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ecc93b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "& \\text{Now, suppose we have a situation such as} \\hspace{.1cm} \\mathbb{P} (white | union) > \\mathbb{P} (Black | union) \\newline\n",
       "& \\text{Rewrite each of these using Bayes' theorem:}\n",
       "= \\frac{\\mathbb{P} (union | white) \\cdot \\mathbb{P}(white)} {\\mathbb{P}(union)} > \\frac{\\mathbb{P} (union | Black) \\cdot \\mathbb{P}(Black)} {\\mathbb{P}(union)} \\newline\n",
       "&= \\mathbb{P} (union | white) \\cdot \\mathbb{P}(white) > \\mathbb{P} (union | Black) \\cdot \\mathbb{P}(Black) \\newline\n",
       "&= \\frac{\\mathbb{P} (union | white)}{{\\mathbb{P} (union | Black )}} > \\frac{\\mathbb{P} (Black)}{\\mathbb{P} (white)}\n",
       "\\\\ &\\text{In other words, if you're more likely to be white if you're a union worker, this only requires} \\newline\n",
       "&\\text{that the ratio by which Black workers exceed white workers' union propensity be less than the overall ratio} \\newline\n",
       "&\\text{of Black to white workers. In this case, Black workers could be twice as likely to be union as white workers (LHS = 0.5)}\n",
       "\\\\ &\\text{but since the ratio of Black to white workers is closer to 0.2, union workers are still more likely to be white}\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "& \\text{Now, suppose we have a situation such as} \\hspace{.1cm} \\mathbb{P} (white | union) > \\mathbb{P} (Black | union) \\newline\n",
    "& \\text{Rewrite each of these using Bayes' theorem:}\n",
    "= \\frac{\\mathbb{P} (union | white) \\cdot \\mathbb{P}(white)} {\\mathbb{P}(union)} > \\frac{\\mathbb{P} (union | Black) \\cdot \\mathbb{P}(Black)} {\\mathbb{P}(union)} \\newline\n",
    "&= \\mathbb{P} (union | white) \\cdot \\mathbb{P}(white) > \\mathbb{P} (union | Black) \\cdot \\mathbb{P}(Black) \\newline\n",
    "&= \\frac{\\mathbb{P} (union | white)}{{\\mathbb{P} (union | Black )}} > \\frac{\\mathbb{P} (Black)}{\\mathbb{P} (white)}\n",
    "\\\\ &\\text{In other words, if you're more likely to be white if you're a union worker, this only requires} \\newline\n",
    "&\\text{that the ratio by which Black workers exceed white workers' union propensity be less than the overall ratio} \\newline\n",
    "&\\text{of Black to white workers. In this case, Black workers could be twice as likely to be union as white workers (LHS = 0.5)}\n",
    "\\\\ &\\text{but since the ratio of Black to white workers is closer to 0.2, union workers are still more likely to be white}\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "efc3da3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "&\\text{A demonstration of how Simpson's paradox is possible for two simple categorical variables:} \\cr\n",
       "&\\text{First, assume that} \\hspace{.1cm} \\overline{X} \\leq \\overline{X+Y} \\leq \\overline{Y} \\cr\n",
       "&\\text{This is probably obvious, but if not, consider that...} \\cr\n",
       "& \\overline{X} \\leq \\overline{Y} \\cr \n",
       "& n_X \\cdot \\overline{X} \\leq n_X \\cdot \\overline{Y} \\cr \n",
       "& n_X \\cdot \\overline{X} + n_Y \\cdot \\overline{Y} \\leq n_X \\cdot \\overline{Y} + n_Y \\cdot \\overline{Y} \\cr \n",
       "& \\sum_{i=1}^n X_i + \\sum_{i=1}^n Y_i \\leq n_X \\cdot \\overline{Y} + n_Y \\cdot \\overline{Y} \\cr \n",
       "& \\frac{\\sum_{i=1}^n X_i + \\sum_{i=1}^n Y_i}{n_X + n_Y} \\leq \\frac{n_X \\cdot \\overline{Y} + n_Y \\cdot \\overline{Y}}{{n_X + n_Y} } \\cr \n",
       "& \\frac{\\sum_{i=1}^n X_i + \\sum_{i=1}^n Y_i}{n_X + n_Y} \\leq \\frac{\\overline{Y} \\cdot (n_X + n_Y)} {(n_X + n_Y)} \\cr \n",
       "& \\overline{X+Y} \\leq \\overline{Y} \\hspace{.1cm} \\text{(The same holds } \\textit{mutatis mutandis } \\text{for} \\hspace{.1cm} \\overline{X}) \\cr\n",
       "\\\\[10pt] & \\text{So, think of X and Y as persons 1 and 2's scores on some variable (two-point shots in our example).}\n",
       "\\\\ & \\text{Then, let A and B represent person 1 and 2's scores on another variable, respectively (e.g. three-point shots). Suppose...} \\cr\n",
       "& \\overline{X} \\leq \\overline{Y} \\hspace{.1cm} \\text{and} \\hspace{.1cm} \\overline{A} \\leq \\overline{B} \\cr\n",
       "& \\text{Then, two scenarios are possible. First, the \"non-paradoxical\" case:} \\cr\n",
       "& \\overline{X} \\leq \\overline{X+A} \\leq \\overline{A} \\leq \\overline{Y} \\leq \\overline{Y+B} \\leq \\overline{B} \\cr\n",
       "& \\text{In that scenario, person 1 scores higher on each variable and the sum of the two variables.} \\cr\n",
       "& \\text{But, another scenario is perfectly possible when the sample size of each variable differs:} \\cr\n",
       "& \\overline{X} \\leq \\overline{Y} \\leq \\overline{Y+B} \\leq \\overline{X+A} \\leq \\overline{A} \\leq \\overline{B} \\cr\n",
       "& \\text{In that case, while person 2 does score better on the first and second variables (verify this above)...} \\cr\n",
       "& \\text{...their mean of scores is closer to the first variable while person 1's mean is closer to the second.} \\cr\n",
       "& \\text{All that is required by arithmetic is that the mean of Y and B be somewhere between them,} \\cr\n",
       "& \\text{and the same be true for X and A; if the mean of A is much larger than Y and close to B} \\cr\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "&\\text{A demonstration of how Simpson's paradox is possible for two simple categorical variables:} \\cr\n",
    "&\\text{First, assume that} \\hspace{.1cm} \\overline{X} \\leq \\overline{X+Y} \\leq \\overline{Y} \\cr\n",
    "&\\text{This is probably obvious, but if not, consider that...} \\cr\n",
    "& \\overline{X} \\leq \\overline{Y} \\cr \n",
    "& n_X \\cdot \\overline{X} \\leq n_X \\cdot \\overline{Y} \\cr \n",
    "& n_X \\cdot \\overline{X} + n_Y \\cdot \\overline{Y} \\leq n_X \\cdot \\overline{Y} + n_Y \\cdot \\overline{Y} \\cr \n",
    "& \\sum_{i=1}^n X_i + \\sum_{i=1}^n Y_i \\leq n_X \\cdot \\overline{Y} + n_Y \\cdot \\overline{Y} \\cr \n",
    "& \\frac{\\sum_{i=1}^n X_i + \\sum_{i=1}^n Y_i}{n_X + n_Y} \\leq \\frac{n_X \\cdot \\overline{Y} + n_Y \\cdot \\overline{Y}}{{n_X + n_Y} } \\cr \n",
    "& \\frac{\\sum_{i=1}^n X_i + \\sum_{i=1}^n Y_i}{n_X + n_Y} \\leq \\frac{\\overline{Y} \\cdot (n_X + n_Y)} {(n_X + n_Y)} \\cr \n",
    "& \\overline{X+Y} \\leq \\overline{Y} \\hspace{.1cm} \\text{(The same holds } \\textit{mutatis mutandis } \\text{for} \\hspace{.1cm} \\overline{X}) \\cr\n",
    "\\\\[10pt] & \\text{So, think of X and Y as persons 1 and 2's scores on some variable (two-point shots in our example).}\n",
    "\\\\ & \\text{Then, let A and B represent person 1 and 2's scores on another variable, respectively (e.g. three-point shots). Suppose...} \\cr\n",
    "& \\overline{X} \\leq \\overline{Y} \\hspace{.1cm} \\text{and} \\hspace{.1cm} \\overline{A} \\leq \\overline{B} \\cr\n",
    "& \\text{Then, two scenarios are possible. First, the \"non-paradoxical\" case:} \\cr\n",
    "& \\overline{X} \\leq \\overline{X+A} \\leq \\overline{A} \\leq \\overline{Y} \\leq \\overline{Y+B} \\leq \\overline{B} \\cr\n",
    "& \\text{In that scenario, person 1 scores higher on each variable and the sum of the two variables.} \\cr\n",
    "& \\text{But, another scenario is perfectly possible when the sample size of each variable differs:} \\cr\n",
    "& \\overline{X} \\leq \\overline{Y} \\leq \\overline{Y+B} \\leq \\overline{X+A} \\leq \\overline{A} \\leq \\overline{B} \\cr\n",
    "& \\text{In that case, while person 2 does score better on the first and second variables (verify this above)...} \\cr\n",
    "& \\text{...their mean of scores is closer to the first variable while person 1's mean is closer to the second.} \\cr\n",
    "& \\text{All that is required by arithmetic is that the mean of Y and B be somewhere between them,} \\cr\n",
    "& \\text{and the same be true for X and A; if the mean of A is much larger than Y and close to B} \\cr\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f5677786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{array}{ll}\n",
       "\\textbf{Univariate measures} & \\textbf{Bivariate measures}\\cr\n",
       "\\\\ Var(X) = \\frac{\\sum (X_i - \\overline{X})^2}{n-1} & Cov(X, Y) = \\frac{\\sum{(X_i - \\overline{X})(Y_i - \\overline{Y})}}{n-1}\n",
       "\\\\ = Cov(X, X) = \\frac{\\sum_{i=1}^n {(X_i - \\overline{X})(X_i - \\overline{X})}}{n-1} & r_{X, Y} = \\frac{\\sum \\frac{(X_i - \\overline{X})}{s_X}\\frac{(Y_i - \\overline{Y})}{s_Y}}{n-1}\n",
       "\\\\ s = \\sqrt{\\frac{\\sum (X_i - \\overline{X})^2}{n-1}} = \\sqrt{Var(X)} &= \\frac{ cov_{X, Y}}{{s_X}{s_Y}}\n",
       "\\\\ &= \\frac{\\sum(X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sqrt{\\sum(X_i - \\bar{X})^2}\n",
       "                                                        \\cdot \\sqrt{\\sum{(Y_i - \\bar{Y})^2}}}\n",
       "\\\\ & \\widehat{\\beta}_1 = r \\cdot \\frac{s_Y}{s_X} \n",
       "\\\\ &= \\frac{ cov_{X, Y}}{{s_X}{s_Y}} \\cdot \\frac{s_Y}{s_X} \n",
       "\\\\ &= \\frac{ cov_{X, Y}}{s^2_X}\n",
       "\\end{array}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{array}{ll}\n",
    "\\textbf{Univariate measures} & \\textbf{Bivariate measures}\\cr\n",
    "\\\\ Var(X) = \\frac{\\sum (X_i - \\overline{X})^2}{n-1} & Cov(X, Y) = \\frac{\\sum{(X_i - \\overline{X})(Y_i - \\overline{Y})}}{n-1}\n",
    "\\\\ Var(X) = \\frac{\\sum (X_i - \\overline{X})^2}{n-1} & Cov(X, Y) = \\frac{\\sum{(X_i - \\overline{X})(Y_i - \\overline{Y})}}{n-1}\n",
    "\\\\ = Cov(X, X) = \\frac{\\sum_{i=1}^n {(X_i - \\overline{X})(X_i - \\overline{X})}}{n-1} & r_{X, Y} = \\frac{\\sum \\frac{(X_i - \\overline{X})}{s_X}\\frac{(Y_i - \\overline{Y})}{s_Y}}{n-1}\n",
    "\\\\ s = \\sqrt{\\frac{\\sum (X_i - \\overline{X})^2}{n-1}} = \\sqrt{Var(X)} &= \\frac{ cov_{X, Y}}{{s_X}{s_Y}}\n",
    "\\\\ &= \\frac{\\sum(X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sqrt{\\sum(X_i - \\bar{X})^2}\n",
    "                                                        \\cdot \\sqrt{\\sum{(Y_i - \\bar{Y})^2}}}\n",
    "\\\\ & \\widehat{\\beta}_1 = r \\cdot \\frac{s_Y}{s_X} \n",
    "\\\\ &= \\frac{ cov_{X, Y}}{{s_X}{s_Y}} \\cdot \\frac{s_Y}{s_X} \n",
    "\\\\ &= \\frac{ cov_{X, Y}}{s^2_X}\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "580c74f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (2408516568.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [2]\u001b[0;36m\u001b[0m\n\u001b[0;31m    \\\\[10pt]r_{X, Y} &= \\frac{\\sum_{i=1}^n \\frac{(X_i - \\bar{X})}{s_X}\\frac{(Y_i - \\bar{Y})}{s_Y}}{n-1}\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "\\\\[10pt]r_{X, Y} &= \\frac{\\sum_{i=1}^n \\frac{(X_i - \\bar{X})}{s_X}\\frac{(Y_i - \\bar{Y})}{s_Y}}{n-1}\n",
    "\\\\[10pt] &= \\frac{ cov_{X, Y}}{{s_X}{s_Y}}\n",
    "\\\\[10pt] &= \\frac{\\sum(X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sqrt{\\sum(X_i - \\bar{X})^2}\n",
    "                                                        \\cdot \\sqrt{\\sum{(Y_i - \\bar{Y})^2}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4db3eacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "&\\textbf{Let M represent our polytomous variable, e.g. religion.} \\cr\n",
       "& \\textbf{Let D represent our indicator.} \\cr\n",
       "& M_i \\in {m} \\hspace{.1cm} \\text{(the little m stands for \"any old value\")} \\cr\n",
       "& D_i \\in \\text{{0, 1}}\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "&\\textbf{Let M represent our polytomous variable, e.g. religion.} \\cr\n",
    "& \\textbf{Let D represent our indicator.} \\cr\n",
    "& M_i \\in {m} \\hspace{.1cm} \\text{(the little m stands for \"any old value\")} \\cr\n",
    "& D_i \\in \\text{{0, 1}}\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38bc7f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "&\\textbf{Point of a dummy variable.} \\cr\n",
       "& M_i \\in {m} \\hspace{.1cm} \\rightarrow D_i \\in \\text{{0, 1}}\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "&\\textbf{Point of a dummy variable.} \\cr\n",
    "& M_i \\in {m} \\hspace{.1cm} \\rightarrow D_i \\in \\text{{0, 1}}\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31e6bfc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "&\\textbf{Mean of a dummy variable} \\cr\n",
       "\\overline{D} &= (n)^{-1} \\cdot \\sum_{i=1}^n D_i \\in {0, 1} \\cr\n",
       "& = (n)^{-1} \\cdot \\hspace{.1cm} [(0_1 + 0_2 + ... 0_{n_0}) \\hspace{.1cm} + \\hspace{.1cm}(1_1 + 1_2 + ... 1_{n_1})] \\cr\n",
       "& = (n)^{-1} \\cdot \\sum_{i=1}^{n_1} 1 \\cr\n",
       "& = (n)^{-1} \\cdot (n_1) \\cr\n",
       "& = \\frac{n_1}{n} \\hspace{.1cm} \\text{(proportion of people who are \"1s\")} \\cr\n",
       "&\\textbf{Sample variance of a dummy variable} \\cr\n",
       "s^2_{D} &= (n-1)^{-1} \\cdot \\sum_{i=1}^n (D_i - \\overline{D})^2 \\cr\n",
       "&= \\widehat{p}(1-\\widehat{p}) \\cdot \\frac{n}{n-1} \\cr\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "&\\textbf{Mean of a dummy variable} \\cr\n",
    "\\overline{D} &= (n)^{-1} \\cdot \\sum_{i=1}^n D_i \\in {0, 1} \\cr\n",
    "& = (n)^{-1} \\cdot \\hspace{.1cm} [(0_1 + 0_2 + ... 0_{n_0}) \\hspace{.1cm} + \\hspace{.1cm}(1_1 + 1_2 + ... 1_{n_1})] \\cr\n",
    "& = (n)^{-1} \\cdot \\sum_{i=1}^{n_1} 1 \\cr\n",
    "& = (n)^{-1} \\cdot (n_1) \\cr\n",
    "& = \\frac{n_1}{n} \\hspace{.1cm} \\text{(proportion of people who are \"1s\")} \\cr\n",
    "&\\textbf{Sample variance of a dummy variable} \\cr\n",
    "s^2_{D} &= (n-1)^{-1} \\cdot \\sum_{i=1}^n (D_i - \\overline{D})^2 \\cr\n",
    "&= \\widehat{p}(1-\\widehat{p}) \\cdot \\frac{n}{n-1} \\cr\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17fa659d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "&\\textbf{Sample variance of a dummy variable} \\cr\n",
       "s^2_{D} &= (n-1)^{-1} \\cdot \\sum_{i=1}^n (D_i - \\overline{D})^2 \\cr\n",
       "&= (n-1)^{-1} \\cdot (\\sum_{i=1}^{n_0} {(0 - \\widehat{p})^2} \\hspace{.1cm} + \\sum_{i=n_0 +1}^{n_1} {(1 - \\widehat{p})^2}) \\cr\n",
       "&= (n-1)^{-1} \\cdot [n_0  {(0 - \\widehat{p})^2} + n_1  {(1 - \\widehat{p})^2}] \\cr\n",
       "&= \\frac{ n_0 \\cdot \\widehat{p}^2}{n-1} + \\frac{n_1 \\cdot (1 - \\widehat{p})^2}{n-1} \\cr\n",
       "\\\\[5pt] &= \\frac{ n_0}{n-1} \\cdot \\widehat{p}^2 + \\frac{n_1}{n-1}  \\cdot (1 - \\widehat{p})^2 \\cr\n",
       "\\ & \\hspace{.5cm} \\frac{n-1}{n} \\leftarrow \\textbf{Let's call that our bias term and multiply by it now} \\cr\n",
       "\\\\[5pt] &= \\frac{n-1}{n} [\\frac{ n_0}{n-1} \\cdot \\widehat{p}^2 + \\frac{n_1}{n-1}  \\cdot (1 - \\widehat{p})^2] \\cr\n",
       "&= (1-p) \\cdot \\widehat{p}^2 + (\\widehat{p})(1-\\widehat{p})^2 \\cr\n",
       "&= \\widehat{p}^2 - \\widehat{p}^3 + (\\widehat{p})(1-2\\widehat{p}+\\widehat{p}^2)\\cr\n",
       "&= \\widehat{p}^2 - \\widehat{p}^3 + (\\widehat{p}-2\\widehat{p}^2+\\widehat{p}^3)\\cr\n",
       "&= (\\widehat{p}-\\widehat{p}^2)\\cr\n",
       "&\\textbf{Recalling that we initially multiplied by our bias term, let's undo that.} \\cr                                          \n",
       "&= \\widehat{p}(1-\\widehat{p}) \\cdot \\frac{n}{n-1} \\cr\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "&\\textbf{Sample variance of a dummy variable} \\cr\n",
    "s^2_{D} &= (n-1)^{-1} \\cdot \\sum_{i=1}^n (D_i - \\overline{D})^2 \\cr\n",
    "&= (n-1)^{-1} \\cdot (\\sum_{i=1}^{n_0} {(0 - \\widehat{p})^2} \\hspace{.1cm} + \\sum_{i=n_0 +1}^{n_1} {(1 - \\widehat{p})^2}) \\cr\n",
    "&= (n-1)^{-1} \\cdot [n_0  {(0 - \\widehat{p})^2} + n_1  {(1 - \\widehat{p})^2}] \\cr\n",
    "&= \\frac{ n_0 \\cdot \\widehat{p}^2}{n-1} + \\frac{n_1 \\cdot (1 - \\widehat{p})^2}{n-1} \\cr\n",
    "\\\\[5pt] &= \\frac{ n_0}{n-1} \\cdot \\widehat{p}^2 + \\frac{n_1}{n-1}  \\cdot (1 - \\widehat{p})^2 \\cr\n",
    "\\ & \\hspace{.5cm} \\frac{n-1}{n} \\leftarrow \\textbf{Let's call that our bias term and multiply by it now} \\cr\n",
    "\\\\[5pt] &= \\frac{n-1}{n} [\\frac{ n_0}{n-1} \\cdot \\widehat{p}^2 + \\frac{n_1}{n-1}  \\cdot (1 - \\widehat{p})^2] \\cr\n",
    "&= (1-p) \\cdot \\widehat{p}^2 + (\\widehat{p})(1-\\widehat{p})^2 \\cr\n",
    "&= \\widehat{p}^2 - \\widehat{p}^3 + (\\widehat{p})(1-2\\widehat{p}+\\widehat{p}^2)\\cr\n",
    "&= \\widehat{p}^2 - \\widehat{p}^3 + (\\widehat{p}-2\\widehat{p}^2+\\widehat{p}^3)\\cr\n",
    "&= (\\widehat{p}-\\widehat{p}^2)\\cr\n",
    "&\\textbf{Recalling that we initially multiplied by our bias term, let's undo that.} \\cr                                          \n",
    "&= \\widehat{p}(1-\\widehat{p}) \\cdot \\frac{n}{n-1} \\cr\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae175304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "& \\mathbb{V}(X) = \\mathbb{E}(X - \\mu)^2 \\cr\n",
       "&= \\mathbb{E}(X^2) - \\mathbb{E}(2X\\mu) + \\mathbb{E}(\\mu)^2 \\cr\n",
       "&= \\mathbb{E}(X^2) - 2\\mathbb{E}(X)\\mu + \\mu^2 \\cr\n",
       "&= \\mathbb{E}(X^2) - 2\\mathbb{E}(X)\\mathbb{E}(X) + [\\mathbb{E}(X)]^2 \\cr\n",
       "&= \\mathbb{E}(X^2) - 2[\\mathbb{E}(X)]^2 + [\\mathbb{E}(X)]^2 \\cr\n",
       "&= \\mathbb{E}(X^2) - [\\mathbb{E}(X)]^2 \\cr\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "& \\mathbb{V}(X) = \\mathbb{E}(X - \\mu)^2 \\cr\n",
    "&= \\mathbb{E}(X^2) - \\mathbb{E}(2X\\mu) + \\mathbb{E}(\\mu)^2 \\cr\n",
    "&= \\mathbb{E}(X^2) - 2\\mathbb{E}(X)\\mu + \\mu^2 \\cr\n",
    "&= \\mathbb{E}(X^2) - 2\\mathbb{E}(X)\\mathbb{E}(X) + [\\mathbb{E}(X)]^2 \\cr\n",
    "&= \\mathbb{E}(X^2) - 2[\\mathbb{E}(X)]^2 + [\\mathbb{E}(X)]^2 \\cr\n",
    "&= \\mathbb{E}(X^2) - [\\mathbb{E}(X)]^2 \\cr\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ae839e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "&\\textbf{Properties of Bernoulli variables} \\cr\n",
       "\\mathbb{E}(X) &= \\sum_{i = min_k}^{max_k} k_i \\cdot p(X = k_i) \\cr\n",
       "\\mathbb{E}(D) &= \\sum_{i = 0}^{1} k_i \\cdot p(D = k_i) \\cr\n",
       "&= 0 \\cdot p(D = 0) + 1 \\cdot p(D = 1) \\cr\n",
       "&= \\Pi \\cr\n",
       "\\\\[10pt] \\mathbb{V}(X) &= \\mathbb{E}(X^2) - [\\mathbb{E}(X)]^2 \\cr\n",
       "\\mathbb{V}(D) &= \\mathbb{E}(D^2) - [\\mathbb{E}(D)]^2 \\cr\n",
       "&= \\mathbb{E}(\\Pi^2) - [\\mathbb{E}(\\Pi)]^2 \\cr\n",
       "&= \\Pi - \\Pi^2 \\cr\n",
       "&= \\Pi(1 - \\Pi) \\cr\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "&\\textbf{Properties of Bernoulli variables} \\cr\n",
    "\\mathbb{E}(X) &= \\sum_{i = min_k}^{max_k} k_i \\cdot p(X = k_i) \\cr\n",
    "\\mathbb{E}(D) &= \\sum_{i = 0}^{1} k_i \\cdot p(D = k_i) \\cr\n",
    "&= 0 \\cdot p(D = 0) + 1 \\cdot p(D = 1) \\cr\n",
    "&= \\Pi \\cr\n",
    "\\\\[10pt] \\mathbb{V}(X) &= \\mathbb{E}(X^2) - [\\mathbb{E}(X)]^2 \\cr\n",
    "\\mathbb{V}(D) &= \\mathbb{E}(D^2) - [\\mathbb{E}(D)]^2 \\cr\n",
    "&= \\mathbb{E}(\\Pi^2) - [\\mathbb{E}(\\Pi)]^2 \\cr\n",
    "&= \\Pi - \\Pi^2 \\cr\n",
    "&= \\Pi(1 - \\Pi) \\cr\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7f754acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "&\\textbf{Regression on a dummy produces group difference in means} \\cr\n",
       "\\widehat{\\beta_1} &= \\frac{cov_{X, Y}}{s_X^2}  \\cr\n",
       "\\\\[2pt] &= \\frac{cov_{X, Y}}{\\widehat{p}(1-\\widehat{p}) \\cdot \\frac{n}{n-1}} \\cr\n",
       "& \\textbf{Temporarily suppress both denominators WLOG. Then,}\n",
       "\\\\[2pt] &= {cov_{D, Y}} = \\sum_{i = 1}^{n_{D=0}} (0-\\widehat{p})(Y_i - \\overline{Y}) + \n",
       "    \\sum_{i = n_{D=0+1}}^{n_{D=1}} (1-\\widehat{p})(Y_i - \\overline{Y})\n",
       "\\\\[2pt] &= (n_{D=0})[-\\widehat{p}*\\overline{Y}_{D=0} + \\widehat{p}*\\overline{Y}] + \n",
       "    (n_{D=1})[\\overline{Y}_{D=1} - \\overline{Y} - \\widehat{p}*\\overline{Y}_{D=1} + \\widehat{p}*\\overline{Y}]\n",
       "\\\\[2pt] &= n* (1-\\widehat{p})*[-\\widehat{p}*\\overline{Y}_{D=0} + \\widehat{p}*\\overline{Y}]+ \n",
       "    n*(\\widehat{p})*[\\overline{Y}_{D=1} - \\overline{Y} - \\widehat{p}*\\overline{Y}_{D=1} + \\widehat{p}*\\overline{Y}] \\cr\n",
       "\\\\[2pt] &= (-n\\widehat{p}\\overline{Y}_{D=0} + n\\widehat{p}\\overline{Y} + n\\widehat{p}^2\\overline{Y}_{D=0} \n",
       "            - n\\widehat{p}^2\\overline{Y}) + (n\\widehat{p}\\overline{Y}_{D=1} -  n\\widehat{p}\\overline{Y} \n",
       "            - n\\widehat{p}^2\\overline{Y}_{D=1} + n\\widehat{p}^2\\overline{Y})\n",
       "\n",
       "\\\\[2pt] &= -n\\widehat{p}\\overline{Y}_{D=0} + n\\widehat{p}^2\\overline{Y}_{D=0} + \n",
       "            n\\widehat{p}\\overline{Y}_{D=1}  - n\\widehat{p}^2\\overline{Y}_{D=1}\n",
       "    \n",
       "\\\\[2pt] &= n\\widehat{p}(\\overline{Y}_{D=1} -\\overline{Y}_{D=0} + \n",
       "        \\widehat{p}\\overline{Y}_{D=0} - \\widehat{p}\\overline{Y}_{D=1})\\cr\n",
       "\n",
       "\\\\[2pt] &= n\\widehat{p}(\\overline{Y}_{D=1} -\\overline{Y}_{D=0})(1 - \\widehat{p}) \\cr\n",
       "\n",
       "\n",
       "& \\textbf{Return both denominators, yielding...} \\cr\n",
       "\\widehat{\\beta_1} &= \\frac{\\frac{{n\\widehat{p}(\\overline{Y}_{D=1} -\\overline{Y}_{D=0})(1 - \\widehat{p})}}{n-1}} \n",
       "    {\\widehat{p}(1 - \\widehat{p})\\frac{n}{(n-1)}}\\cr\n",
       "&= \\overline{Y}_{D=1} -\\overline{Y}_{D=0}  \\cr\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%%latex\n",
    "\\begin{aligned}\n",
    "&\\textbf{Regression on a dummy produces group difference in means} \\cr\n",
    "\\widehat{\\beta_1} &= \\frac{cov_{X, Y}}{s_X^2}  \\cr\n",
    "\\\\[2pt] &= \\frac{cov_{X, Y}}{\\widehat{p}(1-\\widehat{p}) \\cdot \\frac{n}{n-1}} \\cr\n",
    "& \\textbf{Temporarily suppress both denominators WLOG. Then,}\n",
    "\\\\[2pt] &= {cov_{D, Y}} = \\sum_{i = 1}^{n_{D=0}} (0-\\widehat{p})(Y_i - \\overline{Y}) + \n",
    "    \\sum_{i = n_{D=0+1}}^{n_{D=1}} (1-\\widehat{p})(Y_i - \\overline{Y})\n",
    "\\\\[2pt] &= (n_{D=0})[-\\widehat{p}*\\overline{Y}_{D=0} + \\widehat{p}*\\overline{Y}] + \n",
    "    (n_{D=1})[\\overline{Y}_{D=1} - \\overline{Y} - \\widehat{p}*\\overline{Y}_{D=1} + \\widehat{p}*\\overline{Y}]\n",
    "\\\\[2pt] &= n* (1-\\widehat{p})*[-\\widehat{p}*\\overline{Y}_{D=0} + \\widehat{p}*\\overline{Y}]+ \n",
    "    n*(\\widehat{p})*[\\overline{Y}_{D=1} - \\overline{Y} - \\widehat{p}*\\overline{Y}_{D=1} + \\widehat{p}*\\overline{Y}] \\cr\n",
    "\\\\[2pt] &= (-n\\widehat{p}\\overline{Y}_{D=0} + n\\widehat{p}\\overline{Y} + n\\widehat{p}^2\\overline{Y}_{D=0} \n",
    "            - n\\widehat{p}^2\\overline{Y}) + (n\\widehat{p}\\overline{Y}_{D=1} -  n\\widehat{p}\\overline{Y} \n",
    "            - n\\widehat{p}^2\\overline{Y}_{D=1} + n\\widehat{p}^2\\overline{Y})\n",
    "\n",
    "\\\\[2pt] &= -n\\widehat{p}\\overline{Y}_{D=0} + n\\widehat{p}^2\\overline{Y}_{D=0} + \n",
    "            n\\widehat{p}\\overline{Y}_{D=1}  - n\\widehat{p}^2\\overline{Y}_{D=1}\n",
    "    \n",
    "\\\\[2pt] &= n\\widehat{p}(\\overline{Y}_{D=1} -\\overline{Y}_{D=0} + \n",
    "        \\widehat{p}\\overline{Y}_{D=0} - \\widehat{p}\\overline{Y}_{D=1})\\cr\n",
    "\n",
    "\\\\[2pt] &= n\\widehat{p}(\\overline{Y}_{D=1} -\\overline{Y}_{D=0})(1 - \\widehat{p}) \\cr\n",
    "\n",
    "\n",
    "& \\textbf{Return both denominators, yielding...} \\cr\n",
    "\\widehat{\\beta_1} &= \\frac{\\frac{{n\\widehat{p}(\\overline{Y}_{D=1} -\\overline{Y}_{D=0})(1 - \\widehat{p})}}{n-1}} \n",
    "    {\\widehat{p}(1 - \\widehat{p})\\frac{n}{(n-1)}}\\cr\n",
    "&= \\overline{Y}_{D=1} -\\overline{Y}_{D=0}  \\cr\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2904187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "\\text{CI with confidence} \\hspace{.1cm} C = \\overline{X} +/- z_C \\cdot \\frac{\\sigma}{\\sqrt{n}}\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "\\text{CI with confidence} \\hspace{.1cm} C = \\overline{X} +/- z_C \\cdot \\frac{\\sigma}{\\sqrt{n}}\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9582b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "&\\text{Logic of CIs:} \\hspace{.1cm} \\mu \\text{ is implausible if...} \\cr\n",
       "\\ \\mu &> \\overline{X} + z_C \\cdot \\frac{\\sigma}{\\sqrt{n}} \\cr\n",
       "\\ \\mu &< \\overline{X} - z_C \\cdot \\frac{\\sigma}{\\sqrt{n}} \\cr \n",
       "&\\text{...because these inequalities hold C percent of the time} \\cr\n",
       "\\\\[5pt] &\\text{Why CIs work:} \\cr\n",
       "\\ \\mu &< \\overline{X} - z_C \\cdot \\frac{\\sigma}{\\sqrt{n}} < \\mu \\hspace{.1cm} \\text{...C percent of the time.}\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "&\\text{Logic of CIs:} \\hspace{.1cm} \\mu \\text{ is implausible if...} \\cr\n",
    "\\ \\mu &> \\overline{X} + z_C \\cdot \\frac{\\sigma}{\\sqrt{n}} \\cr\n",
    "\\ \\mu &< \\overline{X} - z_C \\cdot \\frac{\\sigma}{\\sqrt{n}} \\cr \n",
    "&\\text{...because these inequalities hold C percent of the time.} \\cr\n",
    "\\\\[5pt] &\\text{Why CIs work:} \\cr\n",
    "\\ \\mu &< \\overline{X} - z_C \\cdot \\frac{\\sigma}{\\sqrt{n}} < \\mu \\hspace{.1cm} \\text{...C percent of the time.}\n",
    "\\\\[5pt] &\\text{Convert to a hypothesis test:} \\cr\n",
    "\\ \\mu &< \\overline{X} - z_C \\cdot \\frac{\\sigma}{\\sqrt{n}} < \\mu \\hspace{.1cm} \\text{...C percent of the time.}\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33118c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "\\ \\mu &< \\overline{X} - z_C \\cdot \\frac{\\sigma}{\\sqrt{n}} < \\mu \\hspace{.1cm} \\text{...C percent of the time.}\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "\\ \\mu &< \\overline{X} - z_C \\cdot \\frac{\\sigma}{\\sqrt{n}} < \\mu \\hspace{.1cm} \\text{...C percent of the time.}\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f141d198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{array}{11}\n",
       "& \\textbf{General variance formula} & \\textbf{Covariance formula}\\cr\n",
       "& \\mathbb{V}(X) = \\mathbb{E}(X - \\mu)^2 & \\mathbb{V}(X, Y) = \\mathbb{E}[(X - \\mu_X)(Y-\\mu_Y)] \\cr\n",
       "&= \\mathbb{E}(X^2) - \\mathbb{E}(2X\\mu) + \\mathbb{E}(\\mu)^2 & = \\mathbb{E}[XY -\\mu_XY - \\mu_YX + \\mu_X\\mu_Y] \\cr\n",
       "&= \\mathbb{E}(X^2) - 2\\mathbb{E}(X)\\mu + \\mu^2 \n",
       "    & = \\mathbb{E}[XY] -\\mathbb{E}[\\mu_XY] - \\mathbb{E}[\\mu_YX] + \\mathbb{E}[\\mu_X\\mu_Y]\\cr\n",
       "&= \\mathbb{E}(X^2) - 2\\mathbb{E}(X)\\mathbb{E}(X) + [\\mathbb{E}(X)]^2 \n",
       "    & = \\mathbb{E}[XY] -\\mu_X\\mathbb{E}[Y] - \\mu_Y\\mathbb{E}[X] + \\mu_X\\mu_Y \\cr\n",
       "&= \\mathbb{E}(X^2) - 2[\\mathbb{E}(X)]^2 + [\\mathbb{E}(X)]^2 \n",
       "    & = \\mathbb{E}[XY] -\\mu_X\\mu_Y - \\mu_Y\\mu_X + \\mu_X\\mu_Y \\cr\n",
       "&= \\mathbb{E}(X^2) - [\\mathbb{E}(X)]^2 \n",
       "    & = \\mathbb{E}[XY] -\\mathbb{E}[X]\\mathbb{E}[Y]\\cr\n",
       "\\end{array}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{array}{11}\n",
    "& \\textbf{General variance formula} & \\textbf{Covariance formula}\\cr\n",
    "& \\mathbb{V}(X) = \\mathbb{E}(X - \\mu)^2 & \\mathbb{V}(X, Y) = \\mathbb{E}[(X - \\mu_X)(Y-\\mu_Y)] \\cr\n",
    "&= \\mathbb{E}(X^2) - \\mathbb{E}(2X\\mu) + \\mathbb{E}(\\mu)^2 & = \\mathbb{E}[XY -\\mu_XY - \\mu_YX + \\mu_X\\mu_Y] \\cr\n",
    "&= \\mathbb{E}(X^2) - 2\\mathbb{E}(X)\\mu + \\mu^2 \n",
    "    & = \\mathbb{E}[XY] -\\mathbb{E}[\\mu_XY] - \\mathbb{E}[\\mu_YX] + \\mathbb{E}[\\mu_X\\mu_Y]\\cr\n",
    "&= \\mathbb{E}(X^2) - 2\\mathbb{E}(X)\\mathbb{E}(X) + [\\mathbb{E}(X)]^2 \n",
    "    & = \\mathbb{E}[XY] -\\mu_X\\mathbb{E}[Y] - \\mu_Y\\mathbb{E}[X] + \\mu_X\\mu_Y \\cr\n",
    "&= \\mathbb{E}(X^2) - 2[\\mathbb{E}(X)]^2 + [\\mathbb{E}(X)]^2 \n",
    "    & = \\mathbb{E}[XY] -\\mu_X\\mu_Y - \\mu_Y\\mu_X + \\mu_X\\mu_Y \\cr\n",
    "&= \\mathbb{E}(X^2) - [\\mathbb{E}(X)]^2 \n",
    "    & = \\mathbb{E}[XY] -\\mathbb{E}[X]\\mathbb{E}[Y]\\cr\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c08dff0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "& \\textbf{Variance of a difference between two random variables} \\cr\n",
       "& \\text{Let Y denote group one's value on some variable and Z denote group two's value} \\cr\n",
       "& \\mathbb{V}(\\overline{Y} - \\overline{Z}) = \\mathbb{E}[(\\overline{Y} - \\overline{Z}) - (\\mu_Y - \\mu_Z)]^2 \\cr\n",
       "& = \\mathbb{E}[(\\overline{Y}^2 - 2\\overline{Y}\\overline{Z} + \\overline{Z}^2) \n",
       "    + (\\mu_Y^2 - 2\\mu_Y\\mu_Z + \\mu_Z^2) -2(\\overline{Y} - \\overline{Z})(\\mu_Y - \\mu_Z)] \\cr\n",
       "& = \\mathbb{E}[\\overline{Y}^2] - \\mathbb{E}[2\\overline{Y}\\overline{Z}] + \\mathbb{E}[\\overline{Z}^2] \n",
       "    + \\mathbb{E}[\\mu_Y]^2 - 2\\mathbb{E}[\\mu_Y\\mu_Z] + \\mathbb{E}[\\mu_Z]^2 \n",
       "    -\\mathbb{E}[2(\\overline{Y}\\mu_Y + \\overline{Z}\\mu_Z - \\overline{Z}\\mu_Y - \\overline{Y}\\mu_Z)]\\cr\n",
       "& = \\mathbb{E}[\\overline{Y}^2] - 2\\mathbb{E}[\\overline{Y}\\overline{Z}] + \\mathbb{E}[\\overline{Z}^2] \n",
       "    + \\mathbb{E}[\\overline{Y}]^2 - 2\\mathbb{E}[\\overline{Y}]\\mathbb{E}[\\overline{Z}] + \\mathbb{E}[\\overline{Z}]^2 \n",
       "    -2\\mathbb{E}[\\overline{Y}]^2 - 2\\mathbb{E}[\\overline{Z}]^2 + 4\\mathbb{E}[\\overline{Y}]\\mathbb{E}[\\overline{Z}] \\cr\n",
       "& = \\mathbb{E}[\\overline{Y}^2] - \\mathbb{E}[\\overline{Y}]^2 + \\mathbb{E}[\\overline{Z}^2] - \\mathbb{E}[\\overline{Z}]^2\n",
       "    - 2\\mathbb{E}[\\overline{Y}]\\mathbb{E}[\\overline{Z}] - 2\\mathbb{E}[\\overline{Y}\\overline{Z}] + 4\\mathbb{E}[\\overline{Y}]\\mathbb{E}[\\overline{Z}] \\cr\n",
       "& = \\mathbb{V}[\\overline{Y}] + \\mathbb{V}[\\overline{Z}]\n",
       "    + 2\\mathbb{E}[\\overline{Y}]\\mathbb{E}[\\overline{Z}] -2\\mathbb{E}[\\overline{Y}\\overline{Z}] \\cr\n",
       "& = \\mathbb{V}[\\overline{Y}] + \\mathbb{V}[\\overline{Z}] - \n",
       "    2(\\mathbb{E}[\\overline{Y}\\overline{Z}] - \\mathbb{E}[\\overline{Y}]\\mathbb{E}[\\overline{Z}]) \\cr\n",
       "& = \\mathbb{V}[\\overline{Y}] + \\mathbb{V}[\\overline{Z}] - 2\\mathbb{COV}(\\overline{Y}, \\overline{Z}) \\cr\n",
       "\\\\[10pt]\n",
       "& \\textbf{Or, using a shortcut developed earlier...} \\cr\n",
       "& \\mathbb{V}(\\overline{Y} - \\overline{Z}) = \\mathbb{E}[(\\overline{Y} - \\overline{Z})^2] - \\mathbb{E}[(\\overline{Y} - \\overline{Z})]^2 \\cr\n",
       "&= \\mathbb{E}[\\overline{Y}^2] + \\mathbb{E}[\\overline{Z}^2] - 2\\mathbb{E}[\\overline{Y}\\overline{Z}] \n",
       "    - \\mathbb{E}[\\overline{Y}]^2 - \\mathbb{E}[\\overline{Z}]^2 + 2\\mathbb{E}[\\overline{Y}]\\mathbb{E}[\\overline{Z}] \\cr\n",
       "&= \\mathbb{V}[\\overline{Y}] + \\mathbb{V}[\\overline{Z}] - 2\\mathbb{E}[\\overline{Y}\\overline{Z}] \n",
       "    + 2\\mathbb{E}[\\overline{Y}]\\mathbb{E}[\\overline{Z}]\\cr\n",
       "&= \\mathbb{V}[\\overline{Y}] + \\mathbb{V}[\\overline{Z}] - 2(\\mathbb{E}[\\overline{Y}\\overline{Z}] \n",
       "    + \\mathbb{E}[\\overline{Y}]\\mathbb{E}[\\overline{Z}]) \\cr\n",
       "& = \\mathbb{V}[\\overline{Y}] + \\mathbb{V}[\\overline{Z}] - 2\\mathbb{COV}(\\overline{Y}, \\overline{Z}) \\cr\n",
       "\\\\[10pt]\n",
       "& \\textbf{Therefore, the standard deviation of a sample mean is...} \\cr\n",
       "& = \\sqrt{\\mathbb{V}[\\overline{Y}] + \\mathbb{V}[\\overline{Z}] - 2\\mathbb{COV}(\\overline{Y}, \\overline{Z})} \\cr\n",
       "& \\textbf{Let's compare this to the implicit standard error using the \"overlapping CI\" method} \\cr\n",
       "& \\text{This method implies comparing two things (suppose z* = 1, so MOE = SE, WLOG)...} \\cr\n",
       "& \\overline{Y}-SE_\\overline{Y} < \\overline{Z} + SE_\\overline{Z} \\cr\n",
       "& \\overline{Y}-SE_\\overline{Y} - (\\overline{Z} + SE_\\overline{Z}) < 0 \\cr\n",
       "& (\\overline{Y} - \\overline{Z}) - (SE_\\overline{Y} + SE_\\overline{Z}) < 0 \\cr\n",
       "& SE_{naïve} = (SE_\\overline{Y} + SE_\\overline{Z}) \\cr\n",
       "& SE_{naïve}^2 = SE_\\overline{Y}^2 + SE_\\overline{Z}^2 + 2(SE_\\overline{Y}+SE_\\overline{Z}) \\cr\n",
       "& \\mathbb{V}[\\overline{Y}] +\\mathbb{V}[\\overline{Z}] + 2(SE_\\overline{Y}+SE_\\overline{Z}) =/=  \\mathbb{V}[\\overline{Y}] + \\mathbb{V}[\\overline{Z}] - 2\\mathbb{COV}(\\overline{Y}, \\overline{Z}) \\cr\n",
       "& \\textbf{This is true even if the term} \\hspace{.1cm} 2\\mathbb{COV}(\\overline{Y}, \\overline{Z}) \\hspace{.1cm} \\textbf{is zero.}\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "& \\textbf{Variance of a difference between two random variables} \\cr\n",
    "& \\text{Let Y denote group one's value on some variable and Z denote group two's value} \\cr\n",
    "& \\mathbb{V}(\\overline{Y} - \\overline{Z}) = \\mathbb{E}[(\\overline{Y} - \\overline{Z}) - (\\mu_Y - \\mu_Z)]^2 \\cr\n",
    "& = \\mathbb{E}[(\\overline{Y}^2 - 2\\overline{Y}\\overline{Z} + \\overline{Z}^2) \n",
    "    + (\\mu_Y^2 - 2\\mu_Y\\mu_Z + \\mu_Z^2) -2(\\overline{Y} - \\overline{Z})(\\mu_Y - \\mu_Z)] \\cr\n",
    "& = \\mathbb{E}[\\overline{Y}^2] - \\mathbb{E}[2\\overline{Y}\\overline{Z}] + \\mathbb{E}[\\overline{Z}^2] \n",
    "    + \\mathbb{E}[\\mu_Y]^2 - 2\\mathbb{E}[\\mu_Y\\mu_Z] + \\mathbb{E}[\\mu_Z]^2 \n",
    "    -\\mathbb{E}[2(\\overline{Y}\\mu_Y + \\overline{Z}\\mu_Z - \\overline{Z}\\mu_Y - \\overline{Y}\\mu_Z)]\\cr\n",
    "& = \\mathbb{E}[\\overline{Y}^2] - 2\\mathbb{E}[\\overline{Y}\\overline{Z}] + \\mathbb{E}[\\overline{Z}^2] \n",
    "    + \\mathbb{E}[\\overline{Y}]^2 - 2\\mathbb{E}[\\overline{Y}]\\mathbb{E}[\\overline{Z}] + \\mathbb{E}[\\overline{Z}]^2 \n",
    "    -2\\mathbb{E}[\\overline{Y}]^2 - 2\\mathbb{E}[\\overline{Z}]^2 + 4\\mathbb{E}[\\overline{Y}]\\mathbb{E}[\\overline{Z}] \\cr\n",
    "& = \\mathbb{E}[\\overline{Y}^2] - \\mathbb{E}[\\overline{Y}]^2 + \\mathbb{E}[\\overline{Z}^2] - \\mathbb{E}[\\overline{Z}]^2\n",
    "    - 2\\mathbb{E}[\\overline{Y}]\\mathbb{E}[\\overline{Z}] - 2\\mathbb{E}[\\overline{Y}\\overline{Z}] + 4\\mathbb{E}[\\overline{Y}]\\mathbb{E}[\\overline{Z}] \\cr\n",
    "& = \\mathbb{V}[\\overline{Y}] + \\mathbb{V}[\\overline{Z}]\n",
    "    + 2\\mathbb{E}[\\overline{Y}]\\mathbb{E}[\\overline{Z}] -2\\mathbb{E}[\\overline{Y}\\overline{Z}] \\cr\n",
    "& = \\mathbb{V}[\\overline{Y}] + \\mathbb{V}[\\overline{Z}] - \n",
    "    2(\\mathbb{E}[\\overline{Y}\\overline{Z}] - \\mathbb{E}[\\overline{Y}]\\mathbb{E}[\\overline{Z}]) \\cr\n",
    "& = \\mathbb{V}[\\overline{Y}] + \\mathbb{V}[\\overline{Z}] - 2\\mathbb{COV}(\\overline{Y}, \\overline{Z}) \\cr\n",
    "\\\\[10pt]\n",
    "& \\textbf{Or, using a shortcut developed earlier...} \\cr\n",
    "& \\mathbb{V}(\\overline{Y} - \\overline{Z}) = \\mathbb{E}[(\\overline{Y} - \\overline{Z})^2] - \\mathbb{E}[(\\overline{Y} - \\overline{Z})]^2 \\cr\n",
    "&= \\mathbb{E}[\\overline{Y}^2] + \\mathbb{E}[\\overline{Z}^2] - 2\\mathbb{E}[\\overline{Y}\\overline{Z}] \n",
    "    - \\mathbb{E}[\\overline{Y}]^2 - \\mathbb{E}[\\overline{Z}]^2 + 2\\mathbb{E}[\\overline{Y}]\\mathbb{E}[\\overline{Z}] \\cr\n",
    "&= \\mathbb{V}[\\overline{Y}] + \\mathbb{V}[\\overline{Z}] - 2\\mathbb{E}[\\overline{Y}\\overline{Z}] \n",
    "    + 2\\mathbb{E}[\\overline{Y}]\\mathbb{E}[\\overline{Z}]\\cr\n",
    "&= \\mathbb{V}[\\overline{Y}] + \\mathbb{V}[\\overline{Z}] - 2(\\mathbb{E}[\\overline{Y}\\overline{Z}] \n",
    "    + \\mathbb{E}[\\overline{Y}]\\mathbb{E}[\\overline{Z}]) \\cr\n",
    "& = \\mathbb{V}[\\overline{Y}] + \\mathbb{V}[\\overline{Z}] - 2\\mathbb{COV}(\\overline{Y}, \\overline{Z}) \\cr\n",
    "\\\\[10pt]\n",
    "& \\textbf{Therefore, the standard deviation of a sample mean is...} \\cr\n",
    "& = \\sqrt{\\mathbb{V}[\\overline{Y}] + \\mathbb{V}[\\overline{Z}] - 2\\mathbb{COV}(\\overline{Y}, \\overline{Z})} \\cr\n",
    "& \\textbf{Let's compare this to the implicit standard error using the \"overlapping CI\" method} \\cr\n",
    "& \\text{This method implies comparing two things (suppose z* = 1, so MOE = SE, WLOG)...} \\cr\n",
    "& \\overline{Y}-SE_\\overline{Y} < \\overline{Z} + SE_\\overline{Z} \\cr\n",
    "& \\overline{Y}-SE_\\overline{Y} - (\\overline{Z} + SE_\\overline{Z}) < 0 \\cr\n",
    "& (\\overline{Y} - \\overline{Z}) - (SE_\\overline{Y} + SE_\\overline{Z}) < 0 \\cr\n",
    "& SE_{naïve} = (SE_\\overline{Y} + SE_\\overline{Z}) \\cr\n",
    "& SE_{naïve}^2 = SE_\\overline{Y}^2 + SE_\\overline{Z}^2 + 2(SE_\\overline{Y}+SE_\\overline{Z}) \\cr\n",
    "& \\mathbb{V}[\\overline{Y}] +\\mathbb{V}[\\overline{Z}] + 2(SE_\\overline{Y}+SE_\\overline{Z}) =/=  \\mathbb{V}[\\overline{Y}] + \\mathbb{V}[\\overline{Z}] - 2\\mathbb{COV}(\\overline{Y}, \\overline{Z}) \\cr\n",
    "& \\textbf{This is true even if the term} \\hspace{.1cm} 2\\mathbb{COV}(\\overline{Y}, \\overline{Z}) \\hspace{.1cm} \\textbf{is zero.}\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99ce6c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "t &= \\frac{(\\overline{Y}-\\overline{Z}) - (\\mu_Y -\\mu_Z)}{\\sqrt{\\frac{s_Y^2}{n_Y} + \\frac{s_Z^2}{n_Z}}} \\cr\n",
       "CI &= (\\overline{Y}-\\overline{Z}) +/- t_c{\\sqrt{\\frac{s_Y^2}{n_Y} + \\frac{s_Z^2}{n_Z}}}\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "t &= \\frac{(\\overline{Y}-\\overline{Z}) - (\\mu_Y -\\mu_Z)}{\\sqrt{\\frac{s_Y^2}{n_Y} + \\frac{s_Z^2}{n_Z}}} \\cr\n",
    "CI &= (\\overline{Y}-\\overline{Z}) +/- t_c{\\sqrt{\\frac{s_Y^2}{n_Y} + \\frac{s_Z^2}{n_Z}}}\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77285416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "z &= \\frac{\\widehat{\\theta} - \\theta_0}{\\sqrt{\\frac{(\\theta_0 \\cdot (1-\\theta_0)}{n}}} \\cr\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "z &= \\frac{\\widehat{\\theta} - \\theta_0}{\\sqrt{\\frac{(\\theta_0 \\cdot (1-\\theta_0)}{n}}} \\cr\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da59a2b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "\\text{CI} &= \\widehat{\\theta} +/- z_c{\\sqrt{\\frac{\\widehat{\\theta} \\cdot (1-\\widehat{\\theta})}{n}}}\\cr\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "\\text{CI} &= \\widehat{\\theta} +/- z_c{\\sqrt{\\frac{\\widehat{\\theta} \\cdot (1-\\widehat{\\theta})}{n}}}\\cr\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20e2a9a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "z &= \\frac{\\widehat{\\theta}_1 - \\widehat{\\theta}_2}\n",
       "    {\\sqrt{\\widehat{\\theta} \\cdot (1-\\widehat{\\theta}) \\cdot (\\frac{1}{n_1} + \\frac{1}{n_2})}} \\cr\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "z &= \\frac{\\widehat{\\theta}_1 - \\widehat{\\theta}_2}\n",
    "    {\\sqrt{\\widehat{\\theta} \\cdot (1-\\widehat{\\theta}) \\cdot (\\frac{1}{n_1} + \\frac{1}{n_2})}} \\cr\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0d651754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "CI &= (\\widehat{\\theta}_1 - \\widehat{\\theta}_2) +/- z_c \\cdot\n",
       "    \\sqrt{\\frac{\\widehat{\\theta}_1 \\cdot (1-\\widehat{\\theta}_1)}{n_1} + \n",
       "    \\frac{\\widehat{\\theta}_2 \\cdot (1-\\widehat{\\theta}_2)}{n_2}} \\cr\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "CI &= (\\widehat{\\theta}_1 - \\widehat{\\theta}_2) +/- z_c \\cdot\n",
    "    \\sqrt{\\frac{\\widehat{\\theta}_1 \\cdot (1-\\widehat{\\theta}_1)}{n_1} + \n",
    "    \\frac{\\widehat{\\theta}_2 \\cdot (1-\\widehat{\\theta}_2)}{n_2}} \\cr\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20cd9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean as least-squares estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "39b656cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "&\\text{Task: minimize the sum of squared residuals associated with a single vector of data,} \\hspace{0.1cm} \n",
       "    \\sum_{i=1}^n \\widehat{u}^2 \\hspace{.1cm} \\text{where} \\hspace{.05cm} \\widehat{u} = X_i - a \\cr\n",
       "&\\text{The simplest approach is to find where the derivative of the function is zero.} \\hspace{.1cm}\n",
       "    \\text{Let} f(x) = \\sum_{i=1}^n (X_i - a)^2. \\text{Then...} \\cr\n",
       "&\\frac{df}{da} = \\frac{d(\\sum_{i=1}^n (X_i^2 - 2aX_i + a^2)}{da} \\cr\n",
       "&= \\frac{d \\sum_{i=1}^n X_i^2}{da} - \\frac{d\\sum_{i=1}^n 2aX_i}{da} + \\frac{d\\sum_{i=1}^n a^2}{da} \\cr\n",
       "&= 0 - 2\\sum_{i=1}^n X_i + 2na \\cr\n",
       "&\\text{Now, set equal to zero...} \\cr\n",
       "& 0 = - 2\\sum_{i=1}^n X_i + 2na \\cr\n",
       "& 2\\sum_{i=1}^n X_i = 2na \\cr\n",
       "& \\sum_{i=1}^n X_i = na \\cr\n",
       "& n\\bar{X} = na \\cr\n",
       "& \\bar{X} = a \\cr\n",
       "& \\text{And, this is a minimum because our function is convex: the second derivative is just 2n, which is necessarily positive.}\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "&\\text{Task: minimize the sum of squared residuals associated with a single vector of data,} \\hspace{0.1cm} \n",
    "    \\sum_{i=1}^n \\widehat{u}^2 \\hspace{.1cm} \\text{where} \\hspace{.05cm} \\widehat{u} = X_i - a \\cr\n",
    "&\\text{The simplest approach is to find where the derivative of the function is zero.} \\hspace{.1cm}\n",
    "    \\text{Let} f(x) = \\sum_{i=1}^n (X_i - a)^2. \\text{Then...} \\cr\n",
    "&\\frac{df}{da} = \\frac{d(\\sum_{i=1}^n (X_i^2 - 2aX_i + a^2)}{da} \\cr\n",
    "&= \\frac{d \\sum_{i=1}^n X_i^2}{da} - \\frac{d\\sum_{i=1}^n 2aX_i}{da} + \\frac{d\\sum_{i=1}^n a^2}{da} \\cr\n",
    "&= 0 - 2\\sum_{i=1}^n X_i + 2na \\cr\n",
    "&\\text{Now, set equal to zero...} \\cr\n",
    "& 0 = - 2\\sum_{i=1}^n X_i + 2na \\cr\n",
    "& 2\\sum_{i=1}^n X_i = 2na \\cr\n",
    "& \\sum_{i=1}^n X_i = na \\cr\n",
    "& n\\bar{X} = na \\cr\n",
    "& \\bar{X} = a \\cr\n",
    "& \\text{And, this is a minimum because our function is convex: the second derivative is just 2n, which is necessarily positive.}\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ef41aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{aligned}\n",
       "&\\text{Task: minimize the sum of squared residuals associated with a single vector of data,} \\hspace{0.1cm} \n",
       "    \\sum_{i=1}^n \\widehat{u}^2 \\hspace{.1cm} \\text{where} \\hspace{.05cm} \\widehat{u} = X_i - q \\cr\n",
       "&\\text{The simplest approach is to find where the derivative of the function is zero.} \\hspace{.1cm}\n",
       "    \\text{Let} f(q) = \\sum_{i=1}^n (X_i - q)^2. \\text{Then...} \\cr\n",
       "& f'(q) = f'(\\sum_{i=1}^n (X_i - q)^2) \\cr\n",
       "&= f'[(X_i - q)^2_1 + (X_i - q)^2_2 + ... + (X_i - q)^2_n] \\cr\n",
       "&= -2(X_i - q)_1 + -2(X_i - q)_2 + ... -2(X_i - q)_n \\cr\n",
       "&= \\sum_{i=1}^n -2(X_i - q) \\cr\n",
       "&\\text{Now, set equal to zero...} \\cr\n",
       "& 0 = \\sum_{i=1}^n -2(X_i - q) \\cr\n",
       "& 0 = -2\\sum_{i=1}^n (X_i - q) \\cr\n",
       "& 0 = \\sum_{i=1}^n X_i - \\sum_{i=1}^n q \\cr\n",
       "& \\sum_{i=1}^n q = \\sum_{i=1}^n X_i \\cr\n",
       "& nq = n\\overline{X} \\cr\n",
       "& q = \\overline{X} \\cr\n",
       "& \\text{And, this is a minimum because our function is convex:} \\cr \n",
       "    & f''(q) = f'[\\sum_{i=1}^n -2(X_i - q)] \\cr\n",
       "    & f''(q) = f'[\\sum_{i=1}^n -2X_i + \\sum_{i=1}^n 2q)] \\cr\n",
       "    & f''(q) = 0_1 + 0_2 + ... 0_2 + 2_1 + 2_2 + ... 2_n \\cr\n",
       "    & f''(q) = 2n \\cr\n",
       "   & \\text{which is necessarily positive.}\n",
       "\\end{aligned}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{aligned}\n",
    "&\\text{Task: minimize the sum of squared residuals associated with a single vector of data,} \\hspace{0.1cm} \n",
    "    \\sum_{i=1}^n \\widehat{u}^2 \\hspace{.1cm} \\text{where} \\hspace{.05cm} \\widehat{u} = X_i - q \\cr\n",
    "&\\text{The simplest approach is to find where the derivative of the function is zero.} \\hspace{.1cm}\n",
    "    \\text{Let} f(q) = \\sum_{i=1}^n (X_i - q)^2. \\text{Then...} \\cr\n",
    "& f'(q) = f'(\\sum_{i=1}^n (X_i - q)^2) \\cr\n",
    "&= f'[(X_i - q)^2_1 + (X_i - q)^2_2 + ... + (X_i - q)^2_n] \\cr\n",
    "&= -2(X_i - q)_1 + -2(X_i - q)_2 + ... -2(X_i - q)_n \\cr\n",
    "&= \\sum_{i=1}^n -2(X_i - q) \\cr\n",
    "&\\text{Now, set equal to zero...} \\cr\n",
    "& 0 = \\sum_{i=1}^n -2(X_i - q) \\cr\n",
    "& 0 = -2\\sum_{i=1}^n (X_i - q) \\cr\n",
    "& 0 = \\sum_{i=1}^n X_i - \\sum_{i=1}^n q \\cr\n",
    "& \\sum_{i=1}^n q = \\sum_{i=1}^n X_i \\cr\n",
    "& nq = n\\overline{X} \\cr\n",
    "& q = \\overline{X} \\cr\n",
    "& \\text{And, this is a minimum because our function is convex:} \\cr \n",
    "    & f''(q) = f'[\\sum_{i=1}^n -2(X_i - q)] \\cr\n",
    "    & f''(q) = f'[\\sum_{i=1}^n -2X_i + \\sum_{i=1}^n 2q)] \\cr\n",
    "    & f''(q) = 0_1 + 0_2 + ... 0_2 + 2_1 + 2_2 + ... 2_n \\cr\n",
    "    & f''(q) = 2n \\cr\n",
    "   & \\text{which is necessarily positive.}\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad68500",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
